---
title: "Sampler Comparison Analysis Using Bayesian Inference - Real Data"
author: "A.J. Brown"
date: "`r Sys.Date()`"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
# load libraries
library(rethinking)
library(dplyr)
library(tidyr)
source("data_sim.r")
```

```{r, echo=FALSE, include=FALSE}}
# changing Stan parameters for speed
# check_cmdstan_toolchain()
cpp_options <- list(
  "CXXFLAGS" = "-Wno-nonnull -D_UCRT -Wno-deprecated-declarations -O1",
  "TBB_CXXFLAGS" = "-D_UCRT",
  "STAN_THREADS" = TRUE,
  PRECOMPILED_HEADERS = TRUE
)
cmdstan_make_local(cpp_options = cpp_options, append = FALSE)
```

```{r}
# rebuild once we have made local changes with all the cores (parallel::detectCores())
rebuild_cmdstan(cores = 8)
```


## Data Import and Preparation
```{r}
# load real data
# TODO: add 2024 data to this 2023 dataset.
# note that this script places the working directory in the 2_code folder, not the root of the project
d <- read.csv("../1_data/real_data.csv")

# drop inflow rows
d <- d[d$event.type != 'Inflow',]
#d <- d[!d$event.count %in% c('Storm 1', 'Storm 2'),]
  
# standardize analytes
d <- d %>%
  group_by(analyte_abbr) %>%
  mutate(result_ctr = standardize(result)) %>%
  ungroup()

# parse data into sub dataframes for each analyte_abbr
d_list <- split(d, d$analyte_abbr)
# dat <- d_list$NO3
# dat <- d_list$NO2
# dat <- d_list$TKN
# dat <- d_list$TP
# dat <- d_list$OP
# dat <- d_list$TSS
# dat <- d_list$EC
# dat <- d_list$pH
# dat <- d_list$TDS

# parse data into sub dataframes for each irrigation
d_list_irr <- split(d, d$event.count)


# our model uses all data at once, no need to split
dat <- d

```

## Model Generation

```{r}
# create data list for ulam models
dlist <- list(
    C_obs = dat$result_ctr, #use standardized results
    S = as.numeric(as.factor(dat$method.name)),
    TRT = as.numeric(as.factor(dat$treatment)),
    I = as.numeric(as.factor(dat$event.count)),
    A = as.numeric(as.factor(dat$analyte_abbr)),
    B = as.numeric(as.factor(dat$block)),
    N = nrow(dat)
)
```

```{r, eval=FALSE, echo=FALSE}
# fit model 1.0, simple model with no partial pooling
m1.0 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        # model
        mu <- a + bS[S] + bTRT[TRT],
        # regular priors
        a ~ dnorm(0,0.2),
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        bA[A] ~ dnorm(0,0.5)
        
        
    ) , data=dlist , chains=4 , cores=4 )
```

```{r, eval=FALSE, echo=FALSE}
# fit model 2.0, 
# using partial pooling around irrigation # (centered)

m2.0 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        
        mu <- a[I] + bA[A] + bS[S] + bTRT[TRT],
        # regular priors
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        bA[A] ~ dnorm(0,0.5),
        # adaptive priors
        a[I] ~ dnorm(a_bar, sigma_a),
        # hyper-priors
        a_bar ~ dnorm(0,0.5),
        sigma_a ~ dexp(1)
        
    ), data=dlist , chains=4 , cores=4)
```

```{r, eval=FALSE, echo=FALSE}
# fit model 2.1, 
# using partial pooling around irrigation # and Analyte (centered)

m2.1 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        
        mu <- a[I] + g[A] + bS[S] + bTRT[TRT],
        # regular priors
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        # adaptive priors
        a[I] ~ dnorm(a_bar, sigma_a),
        g[A] ~ dnorm(g_bar, sigma_g),
        # hyper-priors
        a_bar ~ dnorm(0,0.5),
        g_bar ~ dnorm(0,0.5),
        sigma_a ~ dexp(1),
        sigma_g ~ dexp(1)
        
    ), data=dlist , chains=4 , cores=4)
```

```{r, eval=FALSE, echo=FALSE}
# fit model 2.2
# using partial pooling around irrigation # and Analyte (non-centered)
m2.2 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        # model
        mu <- a_bar + 
              z[I]*sigma_a + # irrigation intercepts
              x[A]*sigma_g + # analyte intercepts
              bS[S] + # sampler method effect
              bTRT[TRT], # treatment effect
        # regular priors
        a_bar ~ dnorm(0,0.5),
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        z[I] ~ dnorm(0,1),
        x[A] ~ dnorm(0,1),
        sigma_a ~ dexp(1),
        sigma_g ~ dexp(1),
        gq> vector[I]:a <<- a_bar + z*sigma_a,
        gq> vector[A]:g <<- x*sigma_g
        # adaptive priors
        # none
        # hyper-priors
        # none
        
    ), data=dlist , chains=4 , cores=4 )
```

```{r, eval=FALSE, echo=FALSE}
# fit model 2.3
# using partial pooling around irrigation # and Analyte, and block (non-centered)
m2.3 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        # model
        mu <- a_bar + 
              z[I]*sigma_a + # irrigation intercepts
              x[A]*sigma_g + # analyte intercepts
              b[B]*sigma_j + # block intercepts
              bS[S] + # sampler method effect
              bTRT[TRT], # treatment effect
        # regular priors
        a_bar ~ dnorm(0,0.5),
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        z[I] ~ dnorm(0,1),
        x[A] ~ dnorm(0,1),
        b[B] ~ dnorm(0,1),
        sigma_a ~ dexp(1),
        sigma_g ~ dexp(1),
        sigma_j ~ dexp(1),
        gq> vector[I]:a <<- a_bar + z*sigma_a,
        gq> vector[A]:g <<- x*sigma_g,
        gq> vector[B]:j <<- b*sigma_j
        # adaptive priors
          # none
        # hyper-priors
          # none
        
    ), data=dlist, chains=4, cores=4 )
```

```{r}
# fit model 2.4
# stratifying by treatment, sampler, and analyte
# using partial pooling around irrigation #, and block (non-centered)
m2.4 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(mu, sigma),
        sigma ~ dexp(1),
        # model
        mu <- a_bar + 
              z[I]*sigma_a + # irrigation intercepts
              b[B]*sigma_j + # block intercepts
              bA[A] + # analyte effect
              bS[S] + # sampler method effect
              bTRT[TRT], # treatment effect
        # regular priors
        a_bar ~ dnorm(0,0.5),
        bA[A] ~ dnorm(0,0.5),
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        z[I] ~ dnorm(0,1),
        b[B] ~ dnorm(0,1),
        sigma_a ~ dexp(1),
        sigma_j ~ dexp(1),
        gq> vector[I]:a <<- a_bar + z*sigma_a,
        gq> vector[B]:j <<- b*sigma_j
        # adaptive priors
          # none
        # hyper-priors
          # none
        
    ), data=dlist, chains=4, cores=4 ) #test running this with threads=2 to speed it up
```

```{r}
# model 2.5
# some notes for this model (in development)
# stratifying by treatment, sampler, and analyte
  # should analyte have it's own slope and intercept? (i.e., bA[A] and g[A])
# using partial pooling around block only
# irrigation is not a cluster (i.e., b/c order matters unlike block)
  # furthermore, irrigations are temporally autocorrelated, so we may need a kernel density simulation
# I think inflow water conc should be a covariate as well, as it influences the concentration of the analyte at the outflow; this will require some df manipulation to make inflow conc associated with each outflow conc
# Storm/Irr should be a covariate as well, as it influences the concentration of the analyte at the outflow
# might need a new DAG here to reflect the above...
# non-centered model
```

```{r, eval=FALSE, echo=FALSE}
# fit model 3.0
# treating C_true as unobserved data
# partial pooling around irrigation # and analyte
# non-centered

m3.0 <- ulam(
    alist(
        # model for C* (observed results)
        C_obs ~ dnorm(C_true, C_sd),
        C_sd ~ dexp(1), # need a prior for C_sd
        
        # model for D (unobserved)
        vector[N]:C_true ~ dnorm(mu , sigma),
        mu <- a_bar + 
              z[I]*sigma_a + # irrigation intercepts
              x[A]*sigma_g + # analyte intercepts
              bS[S] + # sampler method effect
              bTRT[TRT], # treatment effect
        # regular priors
        sigma ~ dexp(1),
        a_bar ~ dnorm(0,0.5),
        bS[S] ~ dnorm(0,0.5),
        bTRT[TRT] ~ dnorm(0,0.5),
        z[I] ~ dnorm(0,1),
        x[A] ~ dnorm(0,1),
        sigma_a ~ dexp(1),
        sigma_g ~ dexp(1),
        gq> vector[I]:a <<- a_bar + z*sigma_a,
        gq> vector[A]:g <<- x*sigma_g
        
    ) , data=dlist , chains=4 , cores=4)
```

## Model Summaries
```{r, eval=FALSE, echo=FALSE}
# model 1.0 - no partial pooling by irrigation
precis(m1.0 , depth=2)
plot(precis(m1.0 , depth=2))
```

```{r, eval=FALSE, echo=FALSE}
# model 2.0 - centered
precis(m2.0 , depth=2)
plot(precis(m2.0 , depth=2))
```

```{r, eval=FALSE, echo=FALSE}
# model 2.1 - centered with analyte pooling
precis(m2.1 , depth=2)
plot(precis(m2.1 , depth=2))
```

```{r, eval=FALSE, echo=FALSE}
# model 2.2 - non-centered 2.1
precis(m2.2, depth=2)
plot(precis(m2.2, depth=2))
```

```{r, eval=FALSE, echo=FALSE}
# model 2.3
precis(m2.3, depth=2)
plot(precis(m2.3, depth=2))
traceplot(m2.3)
```

```{r}
# model 2.4
precis(m2.4, depth=2)
plot(precis(m2.4, depth=2))
#traceplot(m2.4)
trankplot(m2.4)
```


```{r, eval=FALSE, echo=FALSE}
# model 3.0 - true value unobserved
precis(m3.0 , depth=2)
#plot(precis(m3.0 , depth=2))
```

## Graphing Results
```{r}
# extract posterior predictions
#post <- extract.samples(m1.0)
#post <- extract.samples(m2.0)
#post <- extract.samples(m2.1)
#post <- extract.samples(m2.2)
#post <- extract.samples(m2.3)
post <- extract.samples(m2.4)
#post <- extract.samples(m3.0)

# make dataframes
bA_df <- as.data.frame(post$bA)
bA_lng <- pivot_longer(bA_df, cols = c(V1, V2, V3, V4, V5, V6, V7, V8, V9))
bS_df <- as.data.frame(post$bS)
bS_lng <- pivot_longer(bS_df, cols = c(V1, V2, V3, V4))
bTRT_df <- as.data.frame(post$bTRT)
bTRT_lng <- pivot_longer(bTRT_df, cols = c(V1, V2, V3))

# Function to compute summary statistics with 95% CI
compute_summary_with_ci <- function(contrast_df) {
  summary_stats <- apply(contrast_df, 2, function(x) {
    c(
      Min = min(x),
      #`1st Qu.` = quantile(x, 0.25),
      Median = median(x),
      Mean = mean(x),
      #`3rd Qu.` = quantile(x, 0.75),
      Max = max(x),
      `95% CI Lower` = quantile(x, 0.025),
      `95% CI Upper` = quantile(x, 0.975)
    )
  })
  return(as.data.frame(t(summary_stats)))
}
```

### Effect of Sample Method
```{r}
# Find the range of all densities
all_values <- c(bS_df$V1, bS_df$V2, bS_df$V3, bS_df$V4)
x_range <- range(all_values)

# Define the range for x_seq based on the values in all_values
x_seq <- seq(from = x_range[1], to = x_range[2], length.out = 300)

# Calculate the prior density
prior_dens <- dnorm(x_seq, mean = 0, sd = 0.5)

# Find the maximum density value for the y-axis range
max_density <- max(c(
  max(density(bS_df$V1)$y + 0.1),
  max(density(bS_df$V2)$y + 0.1),
  max(density(bS_df$V3)$y + 0.1),
  max(density(bS_df$V4)$y + 0.1),
  max(prior_dens)
))

# Set up the initial plot with the correct x-axis and y-axis ranges using plot()
plot(x_seq, prior_dens, type = 'n', lwd = 2, col = "black", lty = 2, xlim = x_range,
     ylim = c(0, max_density), xlab = "bS (Effect of Sample Method)", ylab = "Density")

# Now plot all densities with the `add = TRUE` parameter
dens(bS_df$V1, lwd=4, col=2, add=TRUE) # Red: Low-Cost Sampler
dens(bS_df$V2, lwd=4, col=4, add=TRUE) # Blue: Grab Sample
dens(bS_df$V3, lwd=4, col=6, add=TRUE) # Purple: Hourly Grab
dens(bS_df$V4, lwd=4, col=8, add=TRUE) # Gray: ISCO

# Add the prior distribution to the plot again
lines(x_seq, prior_dens, lwd = 2, col = "black", lty = 2)

# Add a vertical line at 0
abline(v=0, lty=3)
```

```{r}
# same plot but using ggplot
s_plot <- ggplot(bS_lng, aes(x = value, fill = name)) +
              geom_density(alpha = 0.7) +  # Adjust alpha for transparency if needed
              scale_fill_brewer(palette = "Dark2", 
                                labels = c(
                                           "Low-Cost Sampler", 
                                           "Grab Sample", 
                                           "Hourly Grab", 
                                           "ISCO"
                                           )
                                ) +  # Colorblind-friendly palette
              geom_vline(xintercept = 0, color = "black", linetype = "dashed") +  # Vertical line at zero
              theme_minimal(base_size = 14) +  # White background and base font size
              labs(fill = "Sample Method", x = "Effect of Sampler", y = "Density") +  # Label for legend and axes
              theme(legend.position = "bottom")  # Move legend to bottom

s_plot

```

```{r}
# Compute contrasts in the bS_df between V1, V2, V3, and V4
bS_contrasts_df <- data.frame(
  LCS_vs_GB = bS_df$V1 - bS_df$V2,
  LCS_vs_GBH = bS_df$V1 - bS_df$V3,
  LCS_vs_ISCO = bS_df$V1 - bS_df$V4,
  GB_vs_GBH = bS_df$V2 - bS_df$V3,
  GB_vs_ISCO = bS_df$V2 - bS_df$V4,
  GBH_vs_ISCO = bS_df$V3 - bS_df$V4
)

# Extract contrasts into a matrix or dataframe for easier iteration
contrast_matrix <- as.matrix(bS_contrasts_df)

# Set up an empty plot with appropriate limits and labels
plot(
  NULL, 
  xlim = c(-0.3, 0.3), # Adjust as needed based on your contrast range
  ylim = c(0, 25), 
  xlab = "Contrast of β_S (impact of sampler type on water quality)", 
  ylab = "Density"
)

# Initialize an empty vector to store labels for the legend
legend_labels <- colnames(contrast_matrix)

# Loop over each column (contrast) and plot its density
for (i in 1:ncol(contrast_matrix)) {
  dens(
    contrast_matrix[, i], # Extract the current contrast column
    lwd = 4,              # Line width
    col = i + 1,          # Unique color for each contrast
    add = TRUE            # Overlay the densities
  )
}

# Optional: Add annotations for regions
abline(v = 0, lty = 2) # Vertical dashed line at 0
text(-0.1, 22, "Negative Bias", col = "black", pos = 1) # Adjust text placement
text(0.1, 22, "Positive Bias", col = "black", pos = 1)

# Add a legend
legend(
  "topright",                   # Position of the legend
  legend = legend_labels,       # Labels from column names of the contrast matrix
  col = 2:(ncol(contrast_matrix) + 1), # Corresponding colors
  lwd = 4,                      # Line width matching density lines
  cex = 0.8                     # Adjust text size
)

print(compute_summary_with_ci(bS_contrasts_df))
```


### Effect of Tillage
```{r}
# Find the range of all densities
all_values <- c(bTRT_df$V1, bTRT_df$V2, bTRT_df$V3)
x_range <- range(all_values)

# Define the range for x_seq based on the values in all_values
x_seq <- seq(from = x_range[1], to = x_range[2], length.out = 300)

# Calculate the prior density
prior_dens <- dnorm(x_seq, mean = 0, sd = 0.5)

# Find the maximum density value for the y-axis range
max_density <- max(c(
  max(density(bTRT_df$V1)$y + 0.1),
  max(density(bTRT_df$V2)$y + 0.1),
  max(density(bTRT_df$V3)$y + 0.1),
  max(prior_dens)
))

# Set up the initial plot with the correct x-axis and y-axis ranges using plot()
plot(x_seq, prior_dens, type = 'n', lwd = 2, col = "black", lty = 2, xlim = x_range,
     ylim = c(0, max_density), xlab = "bTRT (Effect of Tillage)", ylab = "Density")

# Now plot all densities with the `add = TRUE` parameter
dens(bTRT_df$V1, lwd=4, col=2, add=TRUE) # Red: CT
dens(bTRT_df$V2, lwd=4, col=4, add=TRUE) # Blue: MT
dens(bTRT_df$V3, lwd=4, col=6, add=TRUE) # Purple: ST

# Add the prior distribution to the plot again
lines(x_seq, prior_dens, lwd = 2, col = "black", lty = 2)

# Add a vertical line at 0
abline(v=0, lty=3)
```

```{r}
# same plot but using ggplot
trt_plot <- ggplot(bTRT_lng, aes(x = value, fill = name)) +
              geom_density(alpha = 0.7) +  # Adjust alpha for transparency if needed
              scale_fill_brewer(palette = "Dark2", labels = c("CT", "MT", "ST")) +  # Colorblind-friendly palette
              geom_vline(xintercept = 0, color = "black", linetype = "dashed") +  # Vertical line at zero
              theme_minimal(base_size = 14) +  # White background and base font size
              labs(fill = "Treatment", x = "Effect of Tillage", y = "Density") +  # Label for legend and axes
              theme(legend.position = "bottom")  # Move legend to bottom

trt_plot

```

```{r}
# Compute contrasts for tillage treatments (CT, MT, ST)
bTRT_contrasts_df <- data.frame(
  CT_vs_MT = bTRT_df$V1 - bTRT_df$V2,
  CT_vs_ST = bTRT_df$V1 - bTRT_df$V3,
  MT_vs_ST = bTRT_df$V2 - bTRT_df$V3
)

# Convert to a matrix for iteration
contrast_matrix <- as.matrix(bTRT_contrasts_df)

# Set up an empty plot with appropriate limits
plot(
  NULL, 
  xlim = range(contrast_matrix),  # Automatically calculate x-axis range
  ylim = c(0, 25),                # Adjust based on density values
  xlab = "Contrast of β_TRT (Effect of Tillage)", 
  ylab = "Density"
)

# Loop over contrasts to plot densities
for (i in 1:ncol(contrast_matrix)) {
  dens(
    contrast_matrix[, i],  # Current contrast
    lwd = 4,               # Line width
    col = i + 1,           # Color for each contrast
    add = TRUE             # Overlay densities
  )
}

# Optional: Add annotations for regions
abline(v = 0, lty = 2) # Vertical dashed line at 0
text(-0.1, 22, "Negative Bias", col = "black", pos = 1) # Adjust text placement
text(0.1, 22, "Positive Bias", col = "black", pos = 1)

# Add a legend
legend(
  "topright", 
  legend = colnames(contrast_matrix),  # Legend labels from column names
  col = 2:(ncol(contrast_matrix) + 1), 
  lwd = 4, 
  cex = 0.8
)

print(compute_summary_with_ci(bTRT_contrasts_df))
```


### Analyte Prediction
```{r}
# make legends for clusters and factors
# Function to generate and print legend for a given column
generate_legend <- function(data, column_name) {
  factor_version <- as.factor(data[[column_name]])
  legend <- setNames(as.character(levels(factor_version)), seq_along(levels(factor_version)))
  cat("\nLegend for", column_name, ":\n")
  print(legend)
}

# Your data frame: dat
# Specify columns for which to generate legends
columns_to_process <- c("analyte_abbr", "event.count", "method.name", "treatment")

# Loop through the specified columns and generate+print legends
for(column_name in columns_to_process) {
  generate_legend(dat, column_name)
}
```

```{r}
# print analytes concentration 89% CI by sample method

# create analyte list for transforming in function later
analyte_list <- levels(factor(dat$analyte_abbr))

# create link function to extract specific predictions
# TODO: can we make this more versitile by using sim() in rethinking package instead of manually specifying model terms?
p_link <- function(posterior_samples, I=1, A=1, S=1, B=1, TRT=1) {
  mu <- with(posterior_samples,
             a[,I] + j[,B] + bA[,A] + bS[,S] + bTRT[,TRT]) # model 2.4
             #a[,I] + g[,A] + j[,B] + bS[,S] + bTRT[,TRT]) # model 2.3
             #a[,I] + g[,A] + bS[,S] + bTRT[,TRT]) # model 2.2
             #a[,I] + bA[,A] + bS[,S] + bTRT[,TRT]) # model 2.0
             #a[,I] + bS[,S] + bTRT[,TRT]) # model 1.0
  # convert back to real units
  mu_analyte <- mean(d_list[[analyte_list[[A]]]]$result)
  sigma_analyte <- sd(d_list[[analyte_list[[A]]]]$result)
  real_mu <- mu * sigma_analyte + mu_analyte
  return(real_mu)
}

p_raw <- sapply(1:4, function(i) p_link(posterior_samples=post, I=1, A=9, S=i, B=2, TRT=2))
p_mu <- apply(p_raw, 2, mean)
p_ci <- apply(p_raw, 2, PI, prob=0.95)
print("Analyte: TSS, Treatment: MT, Irrigation: 1, Block: 2")
print ("1) Grab Sample, 2) Hourly Grab, 3) ISCO, 4) Low-Cost Sampler")
p_mu
p_ci
```

### Calculate and Print Means by Treatment
```{r}
calculate_and_print_means_by_treatment <- function(data) {
  # Get unique levels of treatment
  treatment_levels <- unique(data$treatment)
  
  # Initialize an empty list to store mean results tables
  mean_results_list <- list()
  
  # Iterate over each treatment level
  for(trt in treatment_levels) {
    cat("\nMean Results Table for Treatment:", trt, "\n")
    
    mean_results_table <- data %>%
      filter(treatment == trt) %>%
      group_by(analyte_abbr, method.name, block, event.count) %>%
      summarise(mean_result = mean(result, na.rm = TRUE), .groups = 'drop') %>%
      pivot_wider(names_from = method.name, values_from = mean_result) 
    
    # Print the table for the current treatment level
    print(mean_results_table)
    
    # Store the table in the list with the treatment level as the name
    mean_results_list[[trt]] <- mean_results_table
  }
  
  # Return the list of mean results tables
  return(mean_results_list)
}

mean_results <- calculate_and_print_means_by_treatment(d)
```

```{r}
# Function to plot observed mean on model-generated probability density
plot_posterior_with_observed <- function(analyte_name, treatment_name, block_num, irrigation_event, data, posterior_samples) {
  
  # Map analyte names to indices
  analyte_levels <- levels(as.factor(data$analyte_abbr))
  A <- match(analyte_name, analyte_levels)
  if (is.na(A)) stop("Analyte not found in data.")
  
  # Map treatment names to indices
  treatment_levels <- levels(as.factor(data$treatment))
  TRT <- match(treatment_name, treatment_levels)
  if (is.na(TRT)) stop("Treatment not found in data.")
  
  # Map irrigation events to indices
  irrigation_levels <- levels(as.factor(data$event.count))
  I <- match(irrigation_event, irrigation_levels)
  if (is.na(I)) stop("Irrigation event not found in data.")
  
  # Block number (assuming blocks are numbered consecutively starting from 1)
  B <- block_num
  
  # Sample methods mapping
  method_levels <- levels(as.factor(data$method.name))
  num_methods <- length(method_levels)
  
  # Extract posterior predictions for each sample method
  all_predicted_mu <- list()
  for (S in 1:num_methods) {
    mu_samples <- p_link(posterior_samples, I=I, A=A, S=S, B=B, TRT=TRT)
    mu_samples <- mu_samples[is.finite(mu_samples)]
    if (length(mu_samples) == 0) {
      warning(paste("No finite posterior samples for method:", method_levels[S]))
      next
    }
    all_predicted_mu[[S]] <- mu_samples
  }
  
  # Remove any methods with no predicted samples
  valid_methods <- which(sapply(all_predicted_mu, length) > 0)
  if (length(valid_methods) == 0) {
    stop("No valid posterior predictions to plot.")
  }
  
  method_levels <- method_levels[valid_methods]
  
  # Use the rethinking palette for colors
  rethink_palette <- c("#8080FF", 
                       "#F98400", 
                       "#00A08A", 
                       "#E2AD00", 
                       "#800080", 
                       "#008000", 
                       "#5BBCD6",
                       "#F2AD00", 
                       "#FF0000"
                       )

  
  # Ensure the palette length matches the number of valid methods
  colors <- rethink_palette[1:length(valid_methods)]
  
  # Determine the x and y limits for plotting
  x_min <- min(sapply(all_predicted_mu[valid_methods], min), na.rm=TRUE)
  x_max <- max(sapply(all_predicted_mu[valid_methods], max), na.rm=TRUE)
  
  y_max <- 0
  density_list <- list()
  for (idx in seq_along(valid_methods)) {
    S <- valid_methods[idx]
    mu_samples <- all_predicted_mu[[S]]
    dens_data <- density(mu_samples)
    density_list[[idx]] <- dens_data
    y_max <- max(y_max, max(dens_data$y, na.rm=TRUE))
  }
  
  # Initialize the plot with a general title
  plot(NULL, xlim=c(x_min, x_max), ylim=c(0, y_max * 1.1), 
       xlab="Concentration", ylab="Probability Density", 
       main="Posterior Probability Distributions with Observed Data")
  
  # Add the caption-like text block under the title
  caption_text <- paste("Analyte:", analyte_name, ", Treatment:", treatment_name, 
                        ", Irrigation:", irrigation_event, ", Block:", B)
  mtext(caption_text, side=3, line=0.5, cex=0.9)
  
  # Plot posterior densities and overlay observed means
  for (idx in seq_along(valid_methods)) {
    S <- valid_methods[idx]
    # Plot the posterior density
    dens_data <- density(all_predicted_mu[[S]])
    lines(dens_data$x, dens_data$y, col=colors[idx], lwd=4)
    
    # Extract the observed mean for the current method
    method_name <- method_levels[idx]
    observed_data <- data %>%
      filter(analyte_abbr == analyte_name,
             treatment == treatment_name,
             block == B,
             event.count == irrigation_event,
             method.name == method_name)
    
    if (nrow(observed_data) == 0) {
      warning(paste("No observed data for method:", method_name))
      next
    }
    
    observed_mean <- mean(observed_data$result, na.rm=TRUE)
    
    # Overlay the observed mean as a vertical dashed line
    abline(v=observed_mean, col=colors[idx], lwd=2, lty=2)
  }
  
  # Add a legend to the plot
  legend("topright", legend=method_levels, col=colors, lwd=2, lty=1)
}

```


```{r}
# Plot the posterior distributions with observed (and potentially SWAT+) data
plot_posterior_with_observed(
  analyte_name = "TSS",             # Specify the analyte name
  treatment_name = "CT",            # Specify the treatment name
  block_num = 2,                    # Specify the block number
  irrigation_event = "Irrigation 3",# Specify the irrigation event
  data = d,                         # Your data frame
  posterior_samples = post          # Your posterior samples
)

# Mechanistic prediction and confidence interval bounds
SWAT_prediction <- 1000
x_left <- SWAT_prediction * 0.8   # Lower bound (80% of prediction)
x_right <- SWAT_prediction * 1.15 # Upper bound (115% of prediction)

# Get the current y-axis limits
y_bottom <- par("usr")[3]
y_top <- par("usr")[4]

# Add gray shading between the two vertical lines
rect(x_left, y_bottom, x_right, y_top, 
     col = rgb(0.5, 0.5, 0.5, alpha = 0.3), border = NA)

# Redraw the vertical lines on top of the shading
abline(v = x_left, col = "black", lwd = 2, lty = 3)
abline(v = x_right, col = "black", lwd = 2, lty = 3)

# Add a label near the prediction value
text(x = SWAT_prediction, 
     y = y_top * 0.1,  # Positioning text at 90% of y-axis range
     labels = "SWAT+ 95% CI", 
     col = "black", 
     pos = 4, 
     offset = 1.9)

# Save the plot to a PNG file without affecting the displayed plot
dev.copy(png, filename = "../figs/posterior_with_observed.png", 
         width = 8, height = 6, units = "in", res = 300)
dev.off()

```




## Bar plot graphics with real data
```{r}
# Function to plot results by method and analyte annual average
# To use with real data, just pass your real data frame to the function
# Ensure your real data frame has the same structure, particularly the columns: method.name, analyte_abbr, and result
p_real <- plot_results_by_method_and_analyte(d, title = "Average of Analyte by Sample Method - Real Data")
p_real
ggsave("../figs/summary_real.png", p_real, width = 10, height = 6, units = "in")
```

```{r}
# Plot by irrigation count
# irr 1
p_real_1 <- plot_results_by_method_and_analyte(d_list_irr$`Irrigation 1`, title = "Average of Analyte by Sample Method - Irrigation 1")
p_real_1
ggsave("../figs/summary_real_irr1.png", p_real_1, width = 10, height = 6, units = "in")

# irr 2
p_real_2 <- plot_results_by_method_and_analyte(d_list_irr$`Irrigation 2`, title = "Average of Analyte by Sample Method - Irrigation 2")
p_real_2
ggsave("../figs/summary_real_irr2.png", p_real_2, width = 10, height = 6, units = "in")

# irr 3
p_real_3 <- plot_results_by_method_and_analyte(d_list_irr$`Irrigation 3`, title = "Average of Analyte by Sample Method - Irrigation 3")
p_real_3
ggsave("../figs/summary_real_irr3.png", p_real_3, width = 10, height = 6, units = "in")

# irr 4
p_real_4 <- plot_results_by_method_and_analyte(d_list_irr$`Irrigation 4`, title = "Average of Analyte by Sample Method - Irrigation 4")
p_real_4
ggsave("../figs/summary_real_irr4.png", p_real_4, width = 10, height = 6, units = "in")

# irr 5
p_real_5 <- plot_results_by_method_and_analyte(d_list_irr$`Irrigation 5`, title = "Average of Analyte by Sample Method - Irrigation 5")
p_real_5
ggsave("../figs/summary_real_irr5.png", p_real_5, width = 10, height = 6, units = "in")

# storm 1
p_real_storm1 <- plot_results_by_method_and_analyte(d_list_irr$`Storm 1`, title = "Average of Analyte by Sample Method - Storm 1")
p_real_storm1
ggsave("../figs/summary_real_storm1.png", p_real_storm1, width = 10, height = 6, units = "in")

# storm 2
p_real_storm2 <- plot_results_by_method_and_analyte(d_list_irr$`Storm 2`, title = "Average of Analyte by Sample Method - Storm 2")
p_real_storm2
ggsave("../figs/summary_real_storm2.png", p_real_storm2, width = 10, height = 6, units = "in")
```

```{r}
# Plot by treatment
p_trt <- plot_results_by_treatment_and_analyte(d, title = "Average of Analyte by Tillage Treatment")
p_trt
ggsave("../figs/trt_summary_real.png", p_trt, width = 10, height = 6, units = "in")
```

```{r}
# simple multiple regression for reference between analyte, method, and treatment
library(car)
lm_mod <- lm(result ~ analyte_abbr + method.name + treatment, data = d)
summary(lm_mod)
Anova(lm_mod, type="III")
plot(lm_mod)

#kruskal-wallis test for reference
kruskal.test(result ~ method.name, data = d)
```

