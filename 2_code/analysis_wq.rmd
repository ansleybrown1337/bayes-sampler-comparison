---
title: "Sampler Comparison Analysis Using Bayesian Inference - Simulated Data"
author: "A.J. Brown"
date: "`r Sys.Date()`"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
# load libraries
library(rethinking)
library(dplyr)
library(tidyr)
```

TODO:
- Finish m1.4
- Save plots as images
- Make separate model for flow data
- Update README with final model and results

### Tools
Tool for printing precis() results with key:
```{r}
# Print precis results with sampler type legend
print_precis_with_correct_legend <- function(model, sim_data) {
  # Extract the factor levels from the sampler types in the data
  sampler_types <- levels(as.factor(sim_data$S))
  
  # Print precis results
  precis_results <- precis(model, depth = 2)
  
  # Add a legend mapping sampler type indices to their correct names
  cat("\nLegend:\n")
  for (i in seq_along(sampler_types)) {
    cat(sprintf("  %d = %s\n", i, sampler_types[i]))
  }
  precis_results
}
```

Tool for importing and prepping real data:
```{r}
# load real data
# note that this script places the working directory in the 2_code folder, not the root of the project
d <- read.csv("../1_data/real_data.csv")

# drop inflow rows
d <- d[d$event.type != 'Inflow',]
# we will impute the missing values for the GB, GBH, and ISCO samplers at these events
#d <- d[!d$event.count %in% c('Storm 1', 'Storm 2'),]
  
# standardize analytes
d <- d %>%
  group_by(analyte_abbr) %>%
  mutate(result_ctr = standardize(result),
         C_obs = result) %>%
  ungroup()

# rename block from 1 and 2 to "Block1" and "Block2"
d$block <- factor(d$block, levels = c(1, 2), labels = c("Block1", "Block2"))

# rename sampler names 
#"Grab Sample", "Hourly Grab", "ISCO", "Low-Cost Sampler" to
#"GB", "GBH", "ISCO", "LCS"
d$method.name <- factor(d$method.name, 
                        levels = c("Grab Sample", 
                                   "Hourly Grab", 
                                   "ISCO", 
                                   "Low-Cost Sampler"
                                   ), 
                        labels = c("GB", 
                                   "GBH", 
                                   "ISCO", 
                                   "LCS"
                                   )
                        )
# Create key pairs for consistent mapping with sim data
analyte_mapping <- c(
  "NO3" = 1,
  "NO2" = 2,
  "TKN" = 3,
  "pH" = 4,
  "TP" = 5,
  "OP" = 6,
  "EC" = 7,
  "TSS" = 8,
  "TDS" = 9
)

sampler_mapping <- c(
  "LCS" = 1,
  "ISCO" = 2,
  "GB" = 3,
  "GBH" = 4
)

block_mapping <- c(
  "Block1" = 1,
  "Block2" = 2
)

# Map keys pairs to values in new columns
d <- d %>%
  mutate(A = analyte_mapping[as.character(analyte_abbr)],
         S = sampler_mapping[as.character(method.name)],
         B = block_mapping[as.character(block)]
         )


# our model uses all data at once, no need to split
# Prepare data for the updated model
dat <- list(
  C_obs = d$result_ctr,                      # standardized results
  S = d$S,                                   # Sampler type index (1-4)
  A = d$A,                                   # Analyte index (1-9)
  B = d$B,                                   # Block index (1-2)
  N = nrow(d),                               # Number of observations
  K_S = length(unique(d$S)),                 # Number of sampler types
  K_A = length(unique(d$analyte_abbr)),      # Number of analytes
  K_B = length(unique(d$block))              # Number of blocks
)
```

### Model 1.0 - Intercept Only
Data simulation
```{r, eval=FALSE}
simulate_model_1.0 <- function(n_per_type = 50, noise_sd = 0.2, seed = 42) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Simulate data
  sim_data <- data.frame(
    S = rep(sampler_types, each = n_per_type), # Sampler type
    C_obs = unlist(lapply(sampler_types, function(s) {
      rnorm(n_per_type, mean = true_intercepts[s], sd = noise_sd) # Add measurement noise
    }))
  )
  
  return(sim_data)
}

# Generate simulated data
sim_data_1.0 <- simulate_model_1.0()

```

Model fit
```{r, eval=FALSE}
# fit model 1.0, simple model with no partial pooling
# sim data for this model making the intercept coef have the following values:
# LCS should be 0.7, ISCO should be 0.3, GB should be 1.2 and GBH should be 1.0

# Prepare the data
data1.0 <- list(
  C_obs = sim_data_1.0$C_obs,                    # Observed concentrations
  S = as.numeric(as.factor(sim_data_1.0$S)),     # Sampler types as integers
  N = nrow(sim_data_1.0),                        # Number of observations
  K = length(unique(sim_data_1.0$S))             # Number of sampler types
)

# Fit the model
m1.0 <- ulam(
  alist(
    # Model for observed results
    C_obs ~ dnorm(mu, sigma),
    mu <- a[S],                  # Intercept for sampler type
    a[S] ~ dnorm(0, 0.5),        # Prior for intercepts
    sigma ~ dexp(1)              # Prior for measurement error
  ),
  data = data1.0,
  chains = 4,
  cores = 4
)

```

Summary of results
```{r, eval=FALSE}
# Use the function to display results
print_precis_with_correct_legend(m1.0, sim_data_1.0)
```

Result: The model is able to recover the true intercepts for each sampler type.

### Model 1.1 - Intercept Only with single analyte avg
Data Simulation
```{r, eval=FALSE}
simulate_model_1.1 <- function(n_per_type = 50, noise_sd = 0.2, seed = 42, avg_conc = 8) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Simulate data
  sim_data <- data.frame(
    S = rep(sampler_types, each = n_per_type), # Sampler type
    C_obs = unlist(lapply(sampler_types, function(s) {
      # Observed concentration = analyte average * sampler intercept + noise
      rnorm(n_per_type, mean = true_intercepts[s] * avg_conc, sd = noise_sd)
    }))
  )
  
  # Standardize observed concentrations
  sim_data$C_obs_standardized <- scale(sim_data$C_obs)
  
  # Calculate the z-score equivalents of the true intercepts
  z_scores <- (true_intercepts * avg_conc - mean(sim_data$C_obs)) / sd(sim_data$C_obs)
  
  # Print out the z-score equivalents for verification
  cat("Z-Score Equivalents of True Intercepts:\n")
  for (i in seq_along(sampler_types)) {
    cat(sprintf("  %s: %.3f\n", sampler_types[i], z_scores[i]))
  }
  
  return(sim_data)
}

# Generate simulated data
sim_data_1.1 <- simulate_model_1.1(avg_conc = 8)

```

Model Fit
```{r, eval=FALSE}
# fit model 1.1
# Prepare the data
data1.1 <- list(
  C_obs = standardize(sim_data_1.1$C_obs),       # Standardized Obs concentrations
  S = as.numeric(as.factor(sim_data_1.1$S)),     # Sampler types as integers
  N = nrow(sim_data_1.1),                        # Number of observations
  K = length(unique(sim_data_1.1$S))             # Number of sampler types
)

# Fit Model 1.1
m1.1 <- ulam(
  alist(
    # Model for observed results
    C_obs ~ dnorm(mu, sigma),
    mu <- a[S],                  # Intercept for sampler type
    a[S] ~ dnorm(0, 0.5),        # Prior for intercepts
    sigma ~ dexp(1)              # Prior for measurement error
  ),
  data = data1.1,
  chains = 4,
  cores = 4,
)
```

Summary of results with precis()
```{r, eval=FALSE}
# Use the function to display results
print_precis_with_correct_legend(m1.1, sim_data_1.1)
```

Results: Model 1.1 outputted expected z-scores for the true intercepts of the sampler types. The sampler effect intercepts were correctly estimated, with a correct std. deviation of 0.2.

### Model 1.2 - Multilevel model with sampler and analyte effects
Data simulation 
```{r, eval=FALSE}
simulate_model_1.2 <- function(n_per_type = 100, noise_sd = 0.2, seed = 45) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0) # Multiplicative effects
  
  # Define analytes' base means and standard deviations
  base_means <- c(NO3 = 8, NO2 = 0.1, TKN = 5, pH = 7, TP = 0.8, OP = 0.3, EC = 0.15, TSS = 1000, TDS = 500)
  base_sd <- c(NO3 = 1, NO2 = 0.01, TKN = 1, pH = 0.1, TP = 0.1, OP = 0.05, EC = 0.01, TSS = 200, TDS = 50)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Create all combinations of analytes and sampler types
  sim_data <- expand.grid(
    analyte_abbr = seq_along(base_means), # Numeric index for analytes
    S = sampler_types,
    replicate = seq_len(n_per_type)       # Number of replicates per sampler type
  )
  
  # Map analyte_abbr back to analyte names for clarity
  analyte_map <- names(base_means)
  sim_data$analyte_name <- analyte_map[sim_data$analyte_abbr]
  
  # Generate observed concentrations
  sim_data$C_obs <- mapply(function(analyte, sampler) {
    mean_conc <- base_means[analyte]
    sd_conc <- base_sd[analyte]
    sampler_effect <- true_intercepts[sampler]
    rnorm(1, mean = mean_conc * sampler_effect, sd = sd_conc)
  }, analyte = sim_data$analyte_name, sampler = sim_data$S)
  
  # Standardize observed concentrations by analyte
  sim_data <- sim_data %>%
    group_by(analyte_abbr) %>%
    mutate(
      C_obs_standardized = scale(C_obs), # Standardized concentrations
      mean_obs = mean(C_obs),           # Mean of observed concentrations
      sd_obs = sd(C_obs)                # SD of observed concentrations
    ) %>%
    ungroup()
  
  # Calculate z-score equivalents of true intercepts for each analyte
  z_scores <- matrix(NA, nrow = length(base_means), ncol = length(sampler_types))
  for (idx in seq_along(base_means)) {
    analyte <- names(base_means)[idx]
    mean_conc <- base_means[analyte]
    sd_conc <- base_sd[analyte]
    z_scores[idx, ] <- sapply(sampler_types, function(sampler) {
      true_mean <- mean_conc * true_intercepts[sampler]
      z_score <- (true_mean - mean(sim_data$C_obs[sim_data$analyte_abbr == idx])) / 
                 sd(sim_data$C_obs[sim_data$analyte_abbr == idx])
      return(z_score)
    })
  }
  
  # Assign proper row and column names to z_scores
  dimnames(z_scores) <- list(names(base_means), sampler_types)
  
  # Print z-score equivalents
  cat("Z-Score Equivalents of True Intercepts by Analyte:\n")
  print(z_scores)
  
  # Drop unnecessary replicate column and keep only relevant columns
  sim_data <- sim_data %>% select(analyte_abbr, S, C_obs, C_obs_standardized)
  
  return(sim_data)
}

# Generate simulated data for Model 1.2
sim_data_1.2 <- simulate_model_1.2()

# print averages for C_obs per analyte_abbr stratified by sampler type as separate columns
sim_data_1.2 %>%
  group_by(analyte_abbr, S) %>%
  summarize(mean_C_obs = mean(C_obs), .groups = "drop") %>%
  spread(key = S, value = mean_C_obs) %>%
  print(n = Inf)

```

Model fit
```{r, eval=FALSE}
# Define data for Model 1.2
data1.2 <- list(
  C_obs = sim_data_1.2$C_obs_standardized,      # Standardized observed concentrations
  S = as.numeric(as.factor(sim_data_1.2$S)),    # Sampler type index (1-4)
  A = sim_data_1.2$analyte_abbr,                # Analyte index (1-9)
  N = nrow(sim_data_1.2),                       # Number of observations
  K_S = length(unique(sim_data_1.2$S)),         # Number of sampler types
  K_A = length(unique(sim_data_1.2$analyte_abbr)) # Number of analytes
)

# Fit Model 1.2
m1.2 <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure: interaction between analyte and sampler type
    mu <- alpha[A] + beta[A, S],
    
    # Priors for analyte-specific intercepts
    matrix[A, S]:beta ~ dnorm(0, 0.5),
    alpha[A] ~ dnorm(a_bar, sigma_a),
    
    # Hyper-priors
    a_bar ~ dnorm(0, 0.5),
    sigma_a ~ dexp(1),
    
    # Prior for measurement error
    sigma ~ dexp(1)
  ),
  data = data1.2,
  chains = 4,
  cores = 4
)

```

Summary of results 
```{r, eval=FALSE}
# Use the function to display results
print_precis_with_correct_legend(m1.2, sim_data_1.2)
```

Posterior predictions
```{r, eval=FALSE}
# Extract the posterior samples
post1.2 <- extract.samples(m1.2)

# Create a link function
link_function <- function(post, data) {
  # Extract necessary dimensions
  n_samples <- nrow(post$beta[, , 1])  # Number of posterior samples
  n_analytes <- data$K_A               # Number of analytes
  n_samplers <- data$K_S               # Number of sampler types
  
  # Initialize matrix to store predictions
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers))
  
  # Generate predictions for each analyte-sampler combination
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      predictions[, a, s] <- post$alpha[, a] + post$beta[, a, s]
    }
  }
  
  return(predictions)
}

# Apply the link function to generate posterior predictions
posterior_predictions <- link_function(post1.2, data1.2)

# Back-transform predictions
back_transformed_predictions_1.2 <- array(NA, dim = dim(posterior_predictions))

for (a in 1:data1.2$K_A) {
  # Extract mean and SD for the analyte
  analyte_mean <- mean(sim_data_1.2$C_obs[sim_data_1.2$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.2$C_obs[sim_data_1.2$analyte_abbr == a])
  
  # Back-transform predictions for the analyte
  back_transformed_predictions_1.2[, a, ] <- posterior_predictions[, a, ] * analyte_sd + analyte_mean
}

# Summarize predictions
prediction_summary <- data.frame()

for (a in 1:data1.2$K_A) {
  for (s in 1:data1.2$K_S) {
    # Extract posterior samples for this analyte-sampler combination
    samples <- back_transformed_predictions_1.2[, a, s]
    
    # Compute summary statistics
    summary_row <- data.frame(
      analyte_abbr = a,
      sampler_type = levels(sim_data_1.2$S)[s],
      mean_prediction = mean(samples),
      prediction_5.5 = quantile(samples, 0.055),
      prediction_94.5 = quantile(samples, 0.945)
    )
    
    prediction_summary <- rbind(prediction_summary, summary_row)
  }
}

# View summarized predictions
# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table <- prediction_summary %>%
  select(analyte_abbr, sampler_type, mean_prediction) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table
```

Frequentist Model Equivalent for Sanity Check
```{r, eval=FALSE}
# frequentist model to verify model form
# Fit the linear model
lm_fit <- lm(C_obs ~ as.factor(analyte_abbr) + as.factor(analyte_abbr):S, data = sim_data_1.2)

# Summarize the model
summary(lm_fit)

# Generate predictions using the frequentist linear model
sim_data_1.2$lm_predicted <- predict(lm_fit)

# Summarize predictions into a table
lm_summary_table <- sim_data_1.2 %>%
  group_by(analyte_abbr, S) %>%
  summarize(mean_prediction = mean(lm_predicted), .groups = "drop") %>%
  pivot_wider(names_from = S, values_from = mean_prediction)

lm_summary_table

```

Results: Model 1.2 was successful in estimating analyte and sampler effects in a single model with varying standard deviations correctly.

### Model 1.3 - Multilevel model with sampler, analyte, and block effects
Data simulation
```{r}
simulate_model_1.3 <- function(n_per_type = 100, noise_sd = 0.2, seed = 45) {
  library(dplyr)
  
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0)
  
  # Define analytes' base means and standard deviations
  base_means <- c(NO3 = 8, NO2 = 0.1, TKN = 5, pH = 7, TP = 0.8, OP = 0.3, EC = 0.15, TSS = 1000, TDS = 500)
  base_sd <- c(NO3 = 1, NO2 = 0.01, TKN = 1, pH = 0.1, TP = 0.1, OP = 0.05, EC = 0.01, TSS = 200, TDS = 50)
  
  # Define block-specific effects
  #block_effects <- c(Block1 = 0, Block2 = 0.5)
  block_effects <- c(Block1 = 1, Block2 = 0.8)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Create all combinations of analytes, sampler types, and blocks
  sim_data <- expand.grid(
    analyte_abbr = seq_along(base_means), # Numeric index for analytes
    S = sampler_types,
    block = names(block_effects),
    replicate = seq_len(n_per_type / 2)
  )
  
  # Map analyte_abbr to analyte_name
  analyte_map <- names(base_means)
  sim_data$analyte_name <- analyte_map[sim_data$analyte_abbr]
  
  # Generate observed concentrations
  sim_data <- sim_data %>%
    rowwise() %>%
    mutate(
      C_obs = rnorm(
        1,
        # mean = base_means[analyte_name] * true_intercepts[S] + block_effects[block] * base_sd[analyte_name],
        mean = base_means[analyte_name] +
          (-base_means[analyte_name]*(1-true_intercepts[S])) +
          (-base_means[analyte_name]*(1-block_effects[block])),
        sd = base_sd[analyte_name]
      )
    ) %>%
    ungroup()
  
  # Standardize observed concentrations by analyte
  sim_data <- sim_data %>%
    group_by(analyte_abbr) %>%
    mutate(C_obs_standardized = scale(C_obs)) %>%
    ungroup()
  
  # Select relevant columns
  sim_data <- sim_data %>% select(analyte_abbr, analyte_name, S, block, C_obs, C_obs_standardized)
  
  return(sim_data)
}

# Generate standardized simulated data for Model 1.3
sim_data_1.3 <- simulate_model_1.3()

# Summarize the averages of C_obs per analyte_abbr stratified by sampler type and block
sim_data_1.3 %>%
  group_by(analyte_abbr, analyte_name, S, block) %>%
  summarize(
    mean_C_obs = mean(C_obs),
    .groups = "drop"
  ) %>%
  tidyr::spread(key = S, value = mean_C_obs) %>%
  print(n = Inf)

```

Model fit - TEST DATA
```{r}
# Prepare data for the updated model
data1.3 <- list(
  C_obs = sim_data_1.3$C_obs_standardized,  # Standardized observed concentrations
  S = as.numeric(as.factor(sim_data_1.3$S)), # Sampler type index (1-4)
  A = sim_data_1.3$analyte_abbr,             # Analyte index (1-9)
  B = as.numeric(as.factor(sim_data_1.3$block)), # Block index (1-2)
  N = nrow(sim_data_1.3),                    # Number of observations
  K_S = length(unique(sim_data_1.3$S)),      # Number of sampler types
  K_A = length(unique(sim_data_1.3$analyte_abbr)), # Number of analytes
  K_B = length(unique(sim_data_1.3$block))   # Number of blocks
)

# Updated model allowing block effects to vary by analyte
m1.3 <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure with analyte-specific block effects
    mu <- alpha[A] + beta[A, S] + gamma[A, B],
    
    # Non-centered parameterization for analyte-specific intercepts
    transpars> vector[K_A]:alpha <<- a_bar + z_alpha * sigma_a,
    vector[K_A]:z_alpha ~ normal(0, 1),
    
    # Non-centered parameterization for analyte-specific block effects
    transpars> matrix[K_A, K_B]:gamma <<- g_bar + z_gamma * sigma_g,
    matrix[K_A, K_B]:z_gamma ~ normal(0, 1),
    
    # Priors for sampler-specific effects
    matrix[K_A, K_S]:beta ~ normal(0, 1),
    
    # Hyper-priors
    a_bar ~ normal(0, 1),
    sigma_a ~ exponential(1),
    g_bar ~ normal(0, 0.5),
    sigma_g ~ exponential(1),
    
    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = data1.3,
  chains = 4,
  cores = 4
)

```

Summary of results
```{r}
precis(m1.3, depth=2)
```

```{r}
traceplot(m1.3)
```

Posterior predictions
```{r}
# Extract posterior samples
post1.3 <- extract.samples(m1.3)

# Updated link function for posterior predictions
link_function <- function(post1.3, data) {
  n_samples <- nrow(post1.3$beta[, , 1])  # Number of posterior samples
  n_analytes <- data$K_A               # Number of analytes
  n_samplers <- data$K_S               # Number of sampler types
  n_blocks <- data$K_B                 # Number of blocks
  
  # Initialize predictions array
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers, n_blocks))
  
  # Generate predictions
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      for (b in 1:n_blocks) {
        # Compute predictions in z-score form
        predictions[, a, s, b] <- post1.3$a_bar +
                                  post1.3$z_alpha[, a] * post1.3$sigma_a +
                                  post1.3$beta[, a, s] +
                                  post1.3$g_bar +
                                  post1.3$z_gamma[, a, b] * post1.3$sigma_g
      }
    }
  }
  
  return(predictions)
}

# Generate predictions
posterior_predictions <- link_function(post1.3, data1.3)

# Initialize array for back-transformed predictions
back_transformed_predictions_1.3 <- array(NA, dim = dim(posterior_predictions))

# Back-transform predictions for each analyte
for (a in 1:data1.3$K_A) {
  # Extract mean and SD for the analyte
  analyte_mean <- mean(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  
  # Back-transform predictions for the analyte
  back_transformed_predictions_1.3[, a, , ] <- posterior_predictions[, a, , ] * analyte_sd + analyte_mean
}


# Summarize posterior predictions
# Initialize a summary dataframe
prediction_summary <- data.frame()

# Summarize predictions for each analyte, sampler, and block
for (a in 1:data1.3$K_A) {
  for (s in 1:data1.3$K_S) {
    for (b in 1:data1.3$K_B) {
      # Extract samples for the current analyte, sampler, and block
      samples <- back_transformed_predictions1.3[, a, s, b]
      
      # Add summary statistics to the dataframe
      summary_row <- data.frame(
        analyte_abbr = a,
        sampler_type = as.character(levels(sim_data_1.3$S)[s]),
        block = as.character(levels(sim_data_1.3$block)[b]),
        mean_prediction = mean(samples),
        prediction_5.5 = quantile(samples, 0.055),
        prediction_94.5 = quantile(samples, 0.945)
      )
      
      prediction_summary <- rbind(prediction_summary, summary_row)
    }
  }
}

# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table_1.3 <- prediction_summary %>%
  select(analyte_abbr, sampler_type, mean_prediction, block) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table_1.3
```

Results: Model 1.3 now works as expected, with block effects varying by analyte. The refined summary table shows the mean predictions for each analyte, sampler type, and block. The model can be further refined by incorporating multilevel structures for characterizing correlations between the block effects, sampler effects, and analyte-specific intercepts. 

### Model 1.4 - Multilevel model with sampler, analyte, and block effects with MVN distribution between analytes, samplers, and blocks

**In Development**

Data simulation
```{r, eval=FALSE}
#TBD if we want to try simulating correlations between parameters
sim_data_1.4 <- sim_data_1.3
```

Centered Model
- Model fit
```{r, eval=FALSE}
# Prepare data for the model
data1.4 <- list(
  C_obs = sim_data_1.4$C_obs_standardized,  # Standardized observed concentrations
  S = as.numeric(as.factor(sim_data_1.4$S)), # Sampler type index (1-4)
  A = sim_data_1.4$analyte_abbr,             # Analyte index (1-9)
  B = as.numeric(as.factor(sim_data_1.4$block)), # Block index (1-2)
  N = nrow(sim_data_1.4),                    # Number of observations
  K_S = length(unique(sim_data_1.4$S)),      # Number of sampler types
  K_A = length(unique(sim_data_1.4$analyte_abbr)), # Number of analytes
  K_B = length(unique(sim_data_1.4$block))   # Number of blocks
)

# Non-centered version of m1.4 (corrected)
m1.4_c <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure with correlations between analytes, samplers, and blocks
    mu <- alpha[A] + beta[A, S] + gamma[A, B], #these S, A, and B vars need to BE IN THIS ORDER
    
    # Analyte-specific (9 levels) intercepts 
    alpha[A] ~ dnorm(0, 1),
    
    # Analyte-specific (9 levels) sampler (4 levels) effects (centered parameterization) with covariance
    vector[K_S]:beta[A] ~ multi_normal(0, Rho_sampler, sigma_sampler),
    vector[K_B]:gamma[A] ~ multi_normal(0, Rho_block, sigma_block),
    
    # Fixed priors for sampler and block effects
    sigma_sampler ~ dexp(1),  # Prior for scaling sampler effects
    Rho_sampler ~ dlkjcorr(4),  # LKJ prior for sampler effects
    sigma_block ~ dexp(1),  # Prior for scaling block effects
    Rho_block ~ dlkjcorr(4),  # LKJ prior for block effects
    
    # Prior for measurement error
    sigma ~ dexp(1)
  ),
  data = data1.4,
  chains = 4,
  cores = 12, # reduce to 4 for potato computers
  iter = 2000, # total iterations (increase this to try and get better convergence)
  warmup = 1000
)
```

- Summary of results
```{r, eval=FALSE}
precis(m1.4_c, depth = 2)
```

- Posterior Predictions
```{r, eval=FALSE}
# Extract posterior samples
post1.4_c <- extract.samples(m1.4_c)

# Link function for posterior predictions (Centered Model)
link_function_1.4_c <- function(post, data) {
  n_samples <- nrow(post$alpha)      # Number of posterior samples
  n_analytes <- data$K_A            # Number of analytes
  n_samplers <- data$K_S            # Number of sampler types
  n_blocks <- data$K_B              # Number of blocks

  # Initialize an array to store predictions
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers, n_blocks))

  # Generate predictions for each analyte, sampler, and block
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      for (b in 1:n_blocks) {
        predictions[, a, s, b] <- post$alpha[, a] +
                                  post$beta[, a, s] +   # sampler effect for analyte a
                                  post$gamma[, a, b]    # block effect for analyte a
      }
    }
  }

  return(predictions)
}


# Generate predictions for the centered model
posterior_predictions_1.4_c <- link_function_1.4_c(post1.4_c, data1.4)

# Initialize an array for back-transformed predictions
back_transformed_predictions_1.4_c <- posterior_predictions_1.4_c

# Back-transform predictions for each analyte
for (a in 1:data1.4$K_A) {
  analyte_mean <- mean(sim_data_1.4$C_obs[sim_data_1.4$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.4$C_obs[sim_data_1.4$analyte_abbr == a])

  # Apply back-transformation
  back_transformed_predictions_1.4_c[, a, , ] <- 
    posterior_predictions_1.4_c[, a, , ] * analyte_sd + analyte_mean
}

# Summarize posterior predictions
prediction_summary_1.4_c <- data.frame()

for (a in 1:data1.4$K_A) {
  for (s in 1:data1.4$K_S) {
    for (b in 1:data1.4$K_B) {
      samples <- back_transformed_predictions_1.4_c[, a, s, b]
      summary_row <- data.frame(
        analyte_abbr = a,
        sampler_type = s,
        block = b,
        mean_prediction = mean(samples),
        prediction_5.5 = quantile(samples, 0.055),
        prediction_94.5 = quantile(samples, 0.945)
      )
      prediction_summary_1.4_c <- rbind(prediction_summary_1.4_c, summary_row)
    }
  }
}

# Refine the summary table
refined_summary_table_1.4_c <- prediction_summary_1.4_c %>%
  select(analyte_abbr, sampler_type, mean_prediction, block) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

refined_summary_table_1.4_c

```


Non-centered model
- Model fit
```{r, eval=FALSE}
# Prepare data for the model
data1.4 <- list(
  C_obs = sim_data_1.4$C_obs_standardized,  # Standardized observed concentrations
  S = as.numeric(as.factor(sim_data_1.4$S)), # Sampler type index (1-4)
  A = sim_data_1.4$analyte_abbr,             # Analyte index (1-9)
  B = as.numeric(as.factor(sim_data_1.4$block)), # Block index (1-2)
  N = nrow(sim_data_1.4),                    # Number of observations
  K_S = length(unique(sim_data_1.4$S)),      # Number of sampler types
  K_A = length(unique(sim_data_1.4$analyte_abbr)), # Number of analytes
  K_B = length(unique(sim_data_1.4$block))   # Number of blocks
)

# Non-centered version of m1.4 (corrected)
m1.4_nc <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure with correlations between analytes, samplers, and blocks
    mu <- alpha[A] + beta[A, S] + gamma[A, B],
    
    # Analyte-specific (9 levels) intercepts (non-centered parameterization)
    transpars> vector[K_A]:alpha <<- mu_alpha + z_alpha * sigma_alpha,
    vector[K_A]:z_alpha ~ normal(0, 1),  # Non-centered scaling
    mu_alpha ~ normal(0, 1),  # Prior for mean intercepts
    sigma_alpha ~ exponential(1),  # Prior for intercept variation
    
    # Analyte-specific (9 levels) sampler (4 levels) effects (non-centered parameterization)
    transpars> matrix[K_A, K_S]:beta <<- mu_beta + z_beta * diag_pre_multiply(sigma_beta, L_beta),
    transpars> matrix[K_A, K_S]:mu_beta <- rep_matrix(0, K_A, K_S),  # Center at zero
    matrix[K_A, K_S]:z_beta ~ normal(0, 1),  # Standardized effects
    transpars> cholesky_factor_corr[K_S]:L_beta ~ lkj_corr_cholesky(2),  # LKJ prior
    vector[K_S]:sigma_beta ~ exponential(1),  # Prior for scaling sampler effects
    
    # Analyte-specific (9 levels) block (2 levels) effects (non-centered parameterization)
    transpars> matrix[K_A, K_B]:gamma <<- mu_gamma + z_gamma * diag_pre_multiply(sigma_gamma, L_gamma),
    transpars> matrix[K_A, K_B]:mu_gamma <- rep_matrix(0, K_A, K_B),  # Center at zero
    matrix[K_A, K_B]:z_gamma ~ normal(0, 1),  # Standardized effects
    transpars> cholesky_factor_corr[K_B]:L_gamma ~ lkj_corr_cholesky(2),  # LKJ prior
    vector[K_B]:sigma_gamma ~ exponential(1),  # Prior for scaling block effects
    
    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = data1.4,
  chains = 4,
  cores = 12,
  iter = 2000,              # Total iterations (increase this)
  warmup = 1000             # Number of warmup iterations (optional, default is iter/2)
)

```

- Summary of results
```{r, eval=FALSE}
precis(m1.4_nc, depth = 2)
```

- Posterior predictions
```{r, eval=FALSE}
# Extract posterior samples
post1.4_nc <- extract.samples(m1.4_nc)

# Updated link function for posterior predictions
link_function_1.4_nc <- function(post1.4_nc, data) {
  n_samples <- nrow(post1.4_nc$alpha)       # Number of posterior samples
  n_analytes <- data$K_A                # Number of analytes
  n_samplers <- data$K_S                # Number of sampler types
  n_blocks <- data$K_B                  # Number of blocks

  # Initialize predictions array
  predictions_nc <- array(NA, dim = c(n_samples, n_analytes, n_samplers, n_blocks))

  # Generate predictions
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      for (b in 1:n_blocks) {
        # Compute predictions using the new model structure
        predictions_nc[, a, s, b] <- post1.4_nc$mu_alpha +
                                  post1.4_nc$z_alpha[, a] * post1.4_nc$sigma_alpha +
                                  post1.4_nc$beta[, a, s] +
                                  post1.4_nc$gamma[, a, b]
      }
    }
  }

  return(predictions_nc)
}

# Generate predictions
posterior_predictions_1.4_nc <- link_function_1.4_nc(post1.4_nc, data1.4)

# Initialize array for back-transformed predictions
back_transformed_predictions_1.4_nc <- array(NA, dim = dim(posterior_predictions_1.4_nc))

# Back-transform predictions for each analyte
for (a in 1:data1.4$K_A) {
  # Extract mean and SD for the analyte from `sim_data_1.4`
  analyte_mean <- mean(sim_data_1.4$C_obs[sim_data_1.4$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.4$C_obs[sim_data_1.4$analyte_abbr == a])

  # Back-transform predictions for the analyte
  back_transformed_predictions_1.4_nc[, a, , ] <- posterior_predictions_1.4_nc[, a, , ] * analyte_sd + analyte_mean
}

# Summarize posterior predictions
# Initialize a summary dataframe
prediction_summary_1.4_nc <- data.frame()

# Summarize predictions for each analyte, sampler, and block
for (a in 1:data1.4$K_A) {
  for (s in 1:data1.4$K_S) {
    for (b in 1:data1.4$K_B) {
      # Extract samples for the current analyte, sampler, and block
      samples <- back_transformed_predictions_1.4_nc[, a, s, b]

      # Add summary statistics to the dataframe
      summary_row <- data.frame(
        analyte_abbr = a,
        sampler_type = s,
        block = b,
        mean_prediction = mean(samples),
        prediction_5.5 = quantile(samples, 0.055),
        prediction_94.5 = quantile(samples, 0.945)
      )

      prediction_summary_1.4_nc <- rbind(prediction_summary_1.4_nc, summary_row)
    }
  }
}

# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table_1.4_nc <- prediction_summary_1.4_nc %>%
  select(analyte_abbr, sampler_type, mean_prediction, block) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table_1.4_nc

```

Results: 

## Final model selection, graphing, and interpretation - TEST DATA
*In Development*
Select final model and 'observed data' for comparison
```{r}
# Specify the model to use
which_model <- "1.4_nc"  # Potential options: "1.0", "1.1", "1.2", "1.3", "1.4_c", "1.4_nc"

# Dynamically construct variable names and access them using get()
final_model <- get(paste0("m", which_model))  # e.g., "m1.4_nc"
final_post <- get(paste0("post", which_model))  # e.g., "post1.4_nc"
final_post_back_transformed <- get(paste0("back_transformed_predictions_", which_model))  # e.g., "back_transformed_predictions1.4_nc"
final_data <- get(paste0("sim_data_", gsub("_.*", "", which_model)))  # e.g., "sim_data_1.4"

# Export final data if needed
write.csv(final_data, "../1_data/final_sim_wq_data.csv")

```

*Model Summary*
Plot Model Summary and Convergence Diagnostics
```{r}
precis(final_model, depth = 2)
plot(precis(final_model, depth = 2))
```

*Convergence Diagnostics*
```{r}
traceplot(final_model)
#trankplot(final_model)
```

*Plot Sampler Effects from Posterior*
```{r}
# Plot sampler effects with dynamic axis limits
plot_sampler_effects <- function(posterior_samples, sampler_types) {
  # Extract sampler effects from posterior samples
  n_samplers <- dim(posterior_samples$beta)[3]  # Number of sampler types
  n_analytes <- dim(posterior_samples$beta)[2]  # Number of analytes
  n_samples <- dim(posterior_samples$beta)[1]   # Number of posterior samples

  # Average sampler effects across analytes for each sampler
  sampler_effects <- matrix(NA, nrow = n_samples, ncol = n_samplers)
  for (s in 1:n_samplers) {
    sampler_effects[, s] <- rowMeans(posterior_samples$beta[, , s], na.rm = TRUE)  # Average across analytes
  }

  # Define dynamic axis limits
  percent_buffer <- 0.1 # Percentage buffer for axis limits
  x_min <- min(sampler_effects, na.rm = TRUE)
  x_max <- max(sampler_effects, na.rm = TRUE)
  xlim <- c(x_min - percent_buffer * abs(x_min), x_max + percent_buffer * abs(x_max))

  y_max <- 0
  for (s in 1:n_samplers) {
    dens_data <- density(sampler_effects[, s])
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * (1 + percent_buffer))

  # Plot posterior densities for sampler effects
  colors <- c("#8080FF", "#F98400", "#00A08A", "#E2AD00")  # Rethinking palette
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Sampler Effect (averaged over analytes)", ylab = "Density", main = "Posterior Sampler Effects")

  for (s in 1:n_samplers) {
    dens(sampler_effects[, s], col = colors[s], lwd = 3, add = TRUE)
  }

  # Add prior density line
  curve(dnorm(x, mean = 0, sd = 1), from = xlim[1], to = xlim[2], lwd = 2, lty = 2, col = "black", add = TRUE)

  # Add legend
  legend("topright", legend = c(sampler_types, "Prior"), 
         col = c(colors[1:n_samplers], "black"), lwd = 3, lty = c(rep(1, n_samplers), 2))
}

# Example usage
sampler_types <- levels(as.factor(final_data$S))
plot_sampler_effects(
  posterior_samples = final_post, 
  sampler_types = sampler_types
)

```

*Plot Sampler Effect Contrasts*
```{r}
# Plot contrasts of sampler effects with improved axis scaling
plot_sampler_contrasts <- function(posterior_samples, sampler_types) {
  # Extract sampler effects from posterior samples
  n_samplers <- ncol(posterior_samples$beta[1, , ])  # Number of sampler types
  sampler_effects <- matrix(NA, nrow = nrow(posterior_samples$beta[, , 1]), ncol = n_samplers)
  
  for (s in 1:n_samplers) {
    # Compute the mean sampler effect (averaged over analytes)
    sampler_effects[, s] <- rowMeans(posterior_samples$beta[, , s], na.rm = TRUE)
  }
  
  # Compute pairwise contrasts
  contrast_list <- list()
  for (i in 1:(n_samplers - 1)) {
    for (j in (i + 1):n_samplers) {
      contrast_name <- paste(sampler_types[i], "-", sampler_types[j])
      contrast_list[[contrast_name]] <- sampler_effects[, i] - sampler_effects[, j]
    }
  }
  
  # Define dynamic x limits for contrasts with a minimum buffer size
  all_contrasts <- unlist(contrast_list)
  percent_buffer <- 0.1
  min_buffer <- 0.1  # Minimum absolute buffer for padding
  x_min <- min(all_contrasts, na.rm = TRUE)
  x_max <- max(all_contrasts, na.rm = TRUE)
  x_range <- x_max - x_min
  xlim <- c(
    x_min - max(percent_buffer * x_range, min_buffer),
    x_max + max(percent_buffer * x_range, min_buffer)
  )
  
  # Define y limits dynamically
  y_max <- 0
  for (contrast in contrast_list) {
    dens_data <- density(contrast)
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * 1.1)
  
  # Plot posterior densities for contrasts
  colors <- c("#8080FF", "#F98400", "#00A08A", "#E2AD00", "#FF8080", "#80FF80")  # Extended palette
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Contrast Effect", ylab = "Density", main = "Posterior Sampler Contrasts")
  
  contrast_index <- 1
  for (contrast_name in names(contrast_list)) {
    dens(contrast_list[[contrast_name]], col = colors[contrast_index], lwd = 3, add = TRUE)
    contrast_index <- contrast_index + 1
  }
  
  # Add legend
  legend("topright", legend = names(contrast_list), col = colors[1:length(contrast_list)], lwd = 3)
}

# Example usage
plot_sampler_contrasts(
  posterior_samples = final_post, 
  sampler_types = sampler_types
)
```

*Plot Concentration Predictions*
```{r}
# Function to plot prediction distributions with real data overlay, including analyte dictionary
plot_predictions_with_observed <- function(back_transformed_predictions, data, sampler_types, analyte_index, block_index = NULL) {
  # Create a dictionary for analyte names
  analyte_dict <- c("NO3", "NO2", "TKN", "pH", "TP", "OP", "EC", "TSS", "TDS")
  
  # Get the analyte name from the dictionary
  analyte_name <- ifelse(analyte_index > 0 & analyte_index <= length(analyte_dict),
                         analyte_dict[analyte_index],
                         "Unknown")
  
  # Map block levels to numeric indices
  block_levels <- levels(data$block)
  block_name <- if (!is.null(block_index) && is.character(block_index)) {
    block_index <- match(block_index, block_levels)
    if (is.na(block_index)) stop("Invalid block_index provided.")
    block_levels[block_index]
  } else if (!is.null(block_index)) {
    block_levels[block_index]
  } else {
    "All Blocks"
  }
  
  # Extract predictions for the given analyte and block
  n_samplers <- dim(back_transformed_predictions)[3]  # Number of sampler types
  predictions <- list()
  for (s in 1:n_samplers) {
    if (is.null(block_index)) {
      # No block-specific effect
      predictions[[sampler_types[s]]] <- back_transformed_predictions[, analyte_index, s, 1]
    } else {
      # Include block-specific effect
      predictions[[sampler_types[s]]] <- back_transformed_predictions[, analyte_index, s, block_index]
    }
  }
  
  # Define dynamic axis limits
  all_predictions <- unlist(predictions)
  percent_buffer <- 0.1
  x_min <- min(all_predictions, na.rm = TRUE)
  x_max <- max(all_predictions, na.rm = TRUE)
  x_range <- x_max - x_min
  xlim <- c(
    x_min - max(percent_buffer * x_range, 0.1),
    x_max + max(percent_buffer * x_range, 0.1)
  )
  
  y_max <- 0
  for (sampler in sampler_types) {
    dens_data <- density(predictions[[sampler]])
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * 1.1)
  
  # Plot posterior prediction densities
  colors <- c("#8080FF", 
              "#F98400", 
              "#00A08A", 
              "#E2AD00", 
              "#800080", 
              "#008000", 
              "#5BBCD6",
              "#CC79A7", 
              "#AAAAAA"
             )
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Predicted Concentration", ylab = "Density", 
       main = sprintf("Posterior Predictions with Observed Data\nAnalyte: %s, Block: %s", analyte_name, block_name))
  
  for (s in 1:n_samplers) {
    dens(predictions[[sampler_types[s]]], col = colors[s], lwd = 3, add = TRUE)
  }
  
  # Add observed data points, considering block effects
  for (s in 1:n_samplers) {
    observed_data <- data %>%
      filter(analyte_abbr == analyte_index, S == sampler_types[s])
    
    if (!is.null(block_index)) {
      observed_data <- observed_data %>% filter(block == block_levels[block_index])
    }
    
    observed_values <- observed_data$C_obs
    if (length(observed_values) > 0) {
      observed_mean <- mean(observed_values, na.rm = TRUE)
      observed_sd <- sd(observed_values, na.rm = TRUE)
      
      # Overlay observed mean and SD as dashed line and shaded region
      abline(v = observed_mean, col = colors[s], lwd = 2, lty = 2)
      # rect(
      #   observed_mean - observed_sd, 0, 
      #   observed_mean + observed_sd, y_max * 0.1, 
      #   col = adjustcolor(colors[s], alpha.f = 0.3), border = NA
      # )
    }
  }
  
  # Add legend
  legend("topright", legend = sampler_types, col = colors[1:n_samplers], lwd = 3)
}
```

```{r}
plot_predictions_with_observed(
  back_transformed_predictions = final_post_back_transformed,
  data = final_data,
  sampler_types = sampler_types,
  analyte_index = 1,       # Specify the analyte index
  block_index = "Block1"   # Specify the block name
)

```


## Final model selection, graphing, and interpretation - REAL DATA
*In Development*

Run selected model using real data - which imputes missing data from Storm 1,2
```{r}
# data is 'dat' as created from the real data
# Updated model allowing block effects to vary by analyte
m1.3_real <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure with analyte-specific block effects
    mu <- alpha[A] + beta[A, S] + gamma[A, B],
    
    # Non-centered parameterization for analyte-specific intercepts
    transpars> vector[K_A]:alpha <<- a_bar + z_alpha * sigma_a,
    vector[K_A]:z_alpha ~ normal(0, 1),
    
    # Non-centered parameterization for analyte-specific block effects
    transpars> matrix[K_A, K_B]:gamma <<- g_bar + z_gamma * sigma_g,
    matrix[K_A, K_B]:z_gamma ~ normal(0, 1),
    
    # Priors for sampler-specific effects
    matrix[K_A, K_S]:beta ~ normal(0, 1),
    
    # Hyper-priors
    a_bar ~ normal(0, 1),
    sigma_a ~ exponential(1),
    g_bar ~ normal(0, 0.5),
    sigma_g ~ exponential(1),
    
    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = dat,
  chains = 4,
  cores = 4
)
```

Generate posterior predictions and back-transformed predictions
```{r}
# Extract posterior samples
post1.3_real <- extract.samples(m1.3_real)

# Updated link function for posterior predictions
link_function <- function(post1.3_real, data) {
  n_samples <- nrow(post1.3_real$beta[, , 1])  # Number of posterior samples
  n_analytes <- data$K_A               # Number of analytes
  n_samplers <- data$K_S               # Number of sampler types
  n_blocks <- data$K_B                 # Number of blocks
  
  # Initialize predictions array
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers, n_blocks))
  
  # Generate predictions
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      for (b in 1:n_blocks) {
        # Compute predictions in z-score form
        predictions[, a, s, b] <- post1.3_real$a_bar +
                                  post1.3_real$z_alpha[, a] * post1.3_real$sigma_a +
                                  post1.3_real$beta[, a, s] +
                                  post1.3_real$g_bar +
                                  post1.3_real$z_gamma[, a, b] * post1.3_real$sigma_g
      }
    }
  }
  
  return(predictions)
}

# Generate predictions
posterior_predictions <- link_function(post1.3_real, data1.3)

# Initialize array for back-transformed predictions
back_transformed_predictions1.3_real <- array(NA, dim = dim(posterior_predictions))

# Back-transform predictions for each analyte
for (a in 1:data1.3$K_A) {
  # Extract mean and SD for the analyte
  analyte_mean <- mean(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  
  # Back-transform predictions for the analyte
  back_transformed_predictions1.3_real[, a, , ] <- posterior_predictions[, a, , ] * analyte_sd + analyte_mean
}


# Summarize posterior predictions
# Initialize a summary dataframe
prediction_summary <- data.frame()

# Summarize predictions for each analyte, sampler, and block
for (a in 1:data1.3$K_A) {
  for (s in 1:data1.3$K_S) {
    for (b in 1:data1.3$K_B) {
      # Extract samples for the current analyte, sampler, and block
      samples <- back_transformed_predictions1.3_real[, a, s, b]
      
      # Add summary statistics to the dataframe
      summary_row <- data.frame(
        analyte_abbr = a,
        sampler_type = as.character(levels(sim_data_1.3$S)[s]),
        block = as.character(levels(sim_data_1.3$block)[b]),
        mean_prediction = mean(samples),
        prediction_5.5 = quantile(samples, 0.055),
        prediction_94.5 = quantile(samples, 0.945)
      )
      
      prediction_summary <- rbind(prediction_summary, summary_row)
    }
  }
}

# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table <- prediction_summary %>%
  select(analyte_abbr, sampler_type, mean_prediction, block) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table
```

```{r}
# Number of posterior samples
n_samples <- length(post1.3_real$a_bar)  # Should be 2,000

# Number of parameters for alpha, beta, and gamma
K_A <- length(post1.3_real$alpha) / n_samples  # Analytes
K_S <- length(post1.3_real$beta) / (n_samples * K_A)  # Samplers
K_B <- length(post1.3_real$gamma) / (n_samples * K_A)  # Blocks

# Reshape alpha, beta, and gamma into matrices
alpha_matrix <- matrix(post1.3_real$alpha, nrow = n_samples, ncol = K_A)
beta_matrix <- matrix(post1.3_real$beta, nrow = n_samples, ncol = K_A * K_S)
gamma_matrix <- matrix(post1.3_real$gamma, nrow = n_samples, ncol = K_A * K_B)
```

```{r}
# Correlation plot for sampler-specific effects
correlationPlot(
  mat = beta_matrix,
  density = "smooth",
  method = "pearson",
  thin = 500,
  scaleCorText = TRUE,
  main = "Correlation Between Sampler Effects"
)
```

```{r}
# Correlation plot for analyte-specific intercepts
correlationPlot(
  mat = alpha_matrix,
  density = "smooth",
  method = "pearson",
  thin = 500,
  scaleCorText = TRUE,
  main = "Correlation Between Analyte Intercepts"
)
```

```{r}
# Correlation plot for block-specific effects
correlationPlot(
  mat = gamma_matrix,
  density = "smooth",
  method = "pearson",
  thin = 500,
  scaleCorText = TRUE,
  main = "Correlation Between Block Effects"
)
```


Select final model and 'observed data' for comparison
```{r}
final_model <- m1.3_real
final_post <- post1.3_real #put posterior predictions here
final_post_back_transformed <- back_transformed_predictions1.3_real #put back-transformed posterior predictions here
final_data <- d
```

Plot Model Summary and Convergence Diagnostics
*Model Summary*
```{r}
precis(final_model, depth = 2)
plot(precis(final_model, depth = 1))
```

*Convergence Diagnostics*
```{r}
traceplot(final_model)
#trankplot(final_model)
```

*Plot Sampler Effects from Posterior*
```{r}
# Plot sampler effects with dynamic axis limits
plot_sampler_effects <- function(posterior_samples, sampler_mapping) {
  # Extract sampler effects from posterior samples
  n_samplers <- ncol(posterior_samples$beta[1, , ])  # Number of sampler types
  sampler_effects <- matrix(NA, nrow = nrow(posterior_samples$beta[, , 1]), ncol = n_samplers)
  
  for (s in 1:n_samplers) {
    # Compute the mean sampler effect (averaged over analytes)
    sampler_effects[, s] <- rowMeans(posterior_samples$beta[, , s], na.rm = TRUE)
  }
  
  # Define dynamic axis limits
  percent_buffer <- 0.1 # Percentage buffer for axis limits
  x_min <- min(sampler_effects, na.rm = TRUE)
  x_max <- max(sampler_effects, na.rm = TRUE)
  xlim <- c(x_min - percent_buffer * abs(x_min), x_max + percent_buffer * abs(x_max))
  
  y_max <- 0
  for (s in 1:n_samplers) {
    dens_data <- density(sampler_effects[, s])
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * (1 + percent_buffer))
  
  # Map sampler numbers to their abbreviations
  sampler_labels <- names(sampler_mapping)
  
  # Plot posterior densities for sampler effects
  colors <- c("#8080FF", 
              "#F98400", 
              "#00A08A", 
              "#E2AD00", 
              "#800080", 
              "#008000", 
              "#5BBCD6",
              "#CC79A7", 
              "#AAAAAA"
             )
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Sampler Effect", ylab = "Density", main = "Posterior Sampler Effects")
  
  for (s in 1:n_samplers) {
    dens(sampler_effects[, s], col = colors[s], lwd = 3, add = TRUE)
  }
  
  # Add prior density line
  curve(dnorm(x, mean = 0, sd = 1), from = xlim[1], to = xlim[2], lwd = 2, lty = 2, col = "black", add = TRUE)
  
  # Add legend with sampler labels
  legend("topright", legend = c(sampler_types, "Prior"), 
         col = c(colors[1:n_samplers], "black"), 
         lwd = 3, 
         lty = c(rep(1, n_samplers), 2)
         )
}

# Example usage
sampler_mapping <- c("LCS" = 1, "ISCO" = 2, "GB" = 3, "GBH" = 4)
plot_sampler_effects(
  posterior_samples = final_post, 
  sampler_mapping = sampler_mapping
)
```

*Plot Sampler Effect Contrasts*
```{r}
# Plot contrasts of sampler effects with sampler abbreviations
plot_sampler_contrasts <- function(posterior_samples, sampler_mapping) {
  # Extract sampler effects from posterior samples
  n_samplers <- ncol(posterior_samples$beta[1, , ])  # Number of sampler types
  sampler_effects <- matrix(NA, nrow = nrow(posterior_samples$beta[, , 1]), ncol = n_samplers)
  
  for (s in 1:n_samplers) {
    # Compute the mean sampler effect (averaged over analytes)
    sampler_effects[, s] <- rowMeans(posterior_samples$beta[, , s], na.rm = TRUE)
  }
  
  # Map numeric sampler indices to sampler abbreviations
  sampler_labels <- names(sampler_mapping)
  
  # Compute pairwise contrasts
  contrast_list <- list()
  for (i in 1:(n_samplers - 1)) {
    for (j in (i + 1):n_samplers) {
      contrast_name <- paste(sampler_labels[i], "-", sampler_labels[j])  # Use abbreviations
      contrast_list[[contrast_name]] <- sampler_effects[, i] - sampler_effects[, j]
    }
  }
  
  # Define dynamic x limits for contrasts with a minimum buffer size
  all_contrasts <- unlist(contrast_list)
  percent_buffer <- 0.1
  min_buffer <- 0.1  # Minimum absolute buffer for padding
  x_min <- min(all_contrasts, na.rm = TRUE)
  x_max <- max(all_contrasts, na.rm = TRUE)
  x_range <- x_max - x_min
  xlim <- c(
    x_min - max(percent_buffer * x_range, min_buffer),
    x_max + max(percent_buffer * x_range, min_buffer)
  )
  
  # Define y limits dynamically
  y_max <- 0
  for (contrast in contrast_list) {
    dens_data <- density(contrast)
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * 1.1)
  
  # Plot posterior densities for contrasts
  colors <- c("#8080FF", 
              "#F98400", 
              "#00A08A", 
              "#E2AD00", 
              "#800080", 
              "#008000", 
              "#5BBCD6",
              "#CC79A7", 
              "#AAAAAA"
             )
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Contrast Effect", ylab = "Density", main = "Posterior Sampler Contrasts")
  
  contrast_index <- 1
  for (contrast_name in names(contrast_list)) {
    dens(contrast_list[[contrast_name]], col = colors[contrast_index], lwd = 3, add = TRUE)
    contrast_index <- contrast_index + 1
  }
  
  # Add legend with sampler contrasts
  legend("topright", legend = names(contrast_list), col = colors[1:length(contrast_list)], lwd = 3)
}

# Example usage
sampler_mapping <- c("LCS" = 1, "ISCO" = 2, "GB" = 3, "GBH" = 4)
plot_sampler_contrasts(
  posterior_samples = final_post, 
  sampler_mapping = sampler_mapping
)
```

*Plot Concentration Predictions*
```{r}
# Function to plot prediction distributions with real data overlay, including analyte dictionary
plot_predictions_with_observed <- function(back_transformed_predictions, data, sampler_mapping, analyte_index, block_index = NULL) {
  # Create a dictionary for analyte names
  analyte_dict <- c("NO3 (mg/L)", 
                    "NO2 (mg/L)", 
                    "TKN (mg/L)", 
                    "pH", 
                    "TP (mg/L)", 
                    "OP (mg/L)", 
                    "EC (dS/m)", 
                    "TSS (mg/L)", 
                    "TDS (mg/L)")
  
  # Get the analyte name from the dictionary
  analyte_name <- ifelse(analyte_index > 0 & analyte_index <= length(analyte_dict),
                         analyte_dict[analyte_index],
                         "Unknown")
  
  # Map block levels to numeric indices
  block_levels <- levels(data$block)
  block_name <- if (!is.null(block_index) && is.character(block_index)) {
    block_index <- match(block_index, block_levels)
    if (is.na(block_index)) stop("Invalid block_index provided.")
    block_levels[block_index]
  } else if (!is.null(block_index)) {
    block_levels[block_index]
  } else {
    "All Blocks"
  }
  
  # Extract predictions for the given analyte and block
  n_samplers <- dim(back_transformed_predictions)[3]  # Number of sampler types
  predictions <- list()
  sampler_labels <- names(sampler_mapping)  # Use sampler abbreviations
  
  for (s in 1:n_samplers) {
    if (is.null(block_index)) {
      # No block-specific effect
      predictions[[sampler_labels[s]]] <- back_transformed_predictions[, analyte_index, s, 1]
    } else {
      # Include block-specific effect
      predictions[[sampler_labels[s]]] <- back_transformed_predictions[, analyte_index, s, block_index]
    }
  }
  
  # Define dynamic axis limits
  all_predictions <- unlist(predictions)
  percent_buffer <- 0.1
  x_min <- min(all_predictions, na.rm = TRUE)
  x_max <- max(all_predictions, na.rm = TRUE)
  x_range <- x_max - x_min
  xlim <- c(
    x_min - max(percent_buffer * x_range, 0.1),
    x_max + max(percent_buffer * x_range, 0.1)
  )
  
  y_max <- 0
  for (sampler in sampler_labels) {
    dens_data <- density(predictions[[sampler]])
    y_max <- max(y_max, max(dens_data$y, na.rm = TRUE))
  }
  ylim <- c(0, y_max * 1.1)
  
  # Plot posterior prediction densities
  colors <- c("#8080FF", 
              "#F98400", 
              "#00A08A", 
              "#E2AD00", 
              "#800080", 
              "#008000", 
              "#5BBCD6",
              "#CC79A7", 
              "#AAAAAA"
             )
  plot(NULL, xlim = xlim, ylim = ylim, 
       xlab = "Predicted Concentration", ylab = "Density", 
       main = sprintf("Posterior Predictions with Observed Data\nAnalyte: %s, Block: %s", analyte_name, block_name))
  
  for (s in 1:n_samplers) {
    dens(predictions[[sampler_labels[s]]], col = colors[s], lwd = 3, add = TRUE)
  }
  
  # Add observed data points, considering block effects
  for (s in 1:n_samplers) {
    observed_data <- data %>%
      filter(A == analyte_index, S == sampler_mapping[sampler_labels[s]])
    
    if (!is.null(block_index)) {
      observed_data <- observed_data %>% filter(block == block_levels[block_index])
    }
    
    observed_values <- observed_data$C_obs
    
    # Plot observed data points as vertical lines averaged over event
    if (length(observed_values) > 0) {
      observed_mean <- mean(observed_values, na.rm = TRUE)
      observed_sd <- sd(observed_values, na.rm = TRUE)
      # print analyte and mean value
      print(paste(paste(unique(data$analyte_abbr), observed_mean), observed_sd))
      
      # Overlay observed mean
      abline(v = observed_mean, col = colors[s], lwd = 2, lty = 2)
      
      # Overlay SD as shaded region
      # rect(
      #   observed_mean - observed_sd, 0,
      #   observed_mean + observed_sd, y_max * 0.1,
      #   col = adjustcolor(colors[s], alpha.f = 0.3), border = NA
      # )
    }
    
    # Plot ALL observed points - not on by default
    # if (length(observed_values) > 0) {
    #   # Plot each observed value as a vertical line
    #   for (value in observed_values) {
    #     abline(v = value, col = colors[s], lwd = 2, lty = 2)
    #   }
    # }
  }
  
  # Add legend
  legend("topright", legend = sampler_labels, col = colors[1:n_samplers], lwd = 3)
}

```

```{r}
# Example usage
sampler_mapping <- c("LCS" = 1, "ISCO" = 2, "GB" = 3, "GBH" = 4)
plot_predictions_with_observed(
  back_transformed_predictions = final_post_back_transformed, 
  data = d, 
  sampler_mapping = sampler_mapping, 
  analyte_index = 1, 
  block_index = 1
)
```

## Conclusion



