---
title: "Sampler Comparison Analysis Using Bayesian Inference - Simulated Data"
author: "A.J. Brown"
date: "`r Sys.Date()`"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
# load libraries
library(rethinking)
library(dplyr)
library(tidyr)
source("data_sim.r")
```

## Data Import and Preparation
```{r}
# load simulated data for testing
# note that this script places the working directory in the 2_code folder, not the root of the project
#d <- read.csv("../1_data/sim_data.csv")
d <- simulate_data(real_data_path = "../1_data/real_data.csv",
                   export_csv = TRUE, 
                   csv_path = "../1_data/simulated_data.csv")

# standardize result values for each analyte to get on z-score units
d <- d %>%
  group_by(analyte_abbr) %>%
  mutate(result_ctr = standardize(result)) %>%
  ungroup()

# parse data into sub dataframes for each analyte_abbr
d_list <- split(d, d$analyte_abbr)
# dat <- d_list$NO3
# dat <- d_list$NO2
# dat <- d_list$TKN
# dat <- d_list$TP
# dat <- d_list$OP
# dat <- d_list$TSS
# dat <- d_list$EC
# dat <- d_list$pH
# dat <- d_list$TDS

# our model uses all data at once, no need to split
dat <- d

```

## Model Generation

```{r}
# create data list for ulam models
dlist <- list(
    C_obs = dat$result_ctr, #use standardized results
    S = as.numeric(as.factor(dat$method.name)),
    TRT = as.numeric(as.factor(dat$treatment)),
    I = as.numeric(as.factor(dat$event.count)),
    A = as.numeric(as.factor(dat$analyte_abbr)),
    B = as.numeric(as.factor(dat$block)),
    N = nrow(dat)
)
```
### Tools
Tool for printing precis() results with key:
```{r}
# Print precis results with sampler type legend
print_precis_with_correct_legend <- function(model, sim_data) {
  # Extract the factor levels from the sampler types in the data
  sampler_types <- levels(as.factor(sim_data$S))
  
  # Print precis results
  precis_results <- precis(model, depth = 2)
  
  # Add a legend mapping sampler type indices to their correct names
  cat("\nLegend:\n")
  for (i in seq_along(sampler_types)) {
    cat(sprintf("  %d = %s\n", i, sampler_types[i]))
  }
  precis_results
}
```

### Model 1.0 - Intercept Only
Data simulation
```{r}
simulate_model_1.0 <- function(n_per_type = 50, noise_sd = 0.2, seed = 42) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Simulate data
  sim_data <- data.frame(
    S = rep(sampler_types, each = n_per_type), # Sampler type
    C_obs = unlist(lapply(sampler_types, function(s) {
      rnorm(n_per_type, mean = true_intercepts[s], sd = noise_sd) # Add measurement noise
    }))
  )
  
  return(sim_data)
}

# Generate simulated data
sim_data_1.0 <- simulate_model_1.0()

```

Model fit
```{r, eval=FALSE, echo=FALSE}
# fit model 1.0, simple model with no partial pooling
# sim data for this model making the intercept coef have the following values:
# LCS should be 0.7, ISCO should be 0.3, GB should be 1.2 and GBH should be 1.0

# Prepare the data
data1.0 <- list(
  C_obs = sim_data_1.0$C_obs,                    # Observed concentrations
  S = as.numeric(as.factor(sim_data_1.0$S)),     # Sampler types as integers
  N = nrow(sim_data_1.0),                        # Number of observations
  K = length(unique(sim_data_1.0$S))             # Number of sampler types
)

# Fit the model
m1.0 <- ulam(
  alist(
    # Model for observed results
    C_obs ~ dnorm(mu, sigma),
    mu <- a[S],                  # Intercept for sampler type
    a[S] ~ dnorm(0, 0.5),        # Prior for intercepts
    sigma ~ dexp(1)              # Prior for measurement error
  ),
  data = data1.0,
  chains = 4,
  cores = 4
)

```

Summary of results
```{r}
# Use the function to display results
print_precis_with_correct_legend(m1.0, sim_data_1.0)
```

Result: The model is able to recover the true intercepts for each sampler type.

### Model 1.1 - Intercept Only with single analyte avg
Data Simulation
```{r, eval=FALSE, echo=FALSE}
simulate_model_1.1 <- function(n_per_type = 50, noise_sd = 0.2, seed = 42, avg_conc = 8) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Simulate data
  sim_data <- data.frame(
    S = rep(sampler_types, each = n_per_type), # Sampler type
    C_obs = unlist(lapply(sampler_types, function(s) {
      # Observed concentration = analyte average * sampler intercept + noise
      rnorm(n_per_type, mean = true_intercepts[s] * avg_conc, sd = noise_sd)
    }))
  )
  
  # Standardize observed concentrations
  sim_data$C_obs_standardized <- scale(sim_data$C_obs)
  
  # Calculate the z-score equivalents of the true intercepts
  z_scores <- (true_intercepts * avg_conc - mean(sim_data$C_obs)) / sd(sim_data$C_obs)
  
  # Print out the z-score equivalents for verification
  cat("Z-Score Equivalents of True Intercepts:\n")
  for (i in seq_along(sampler_types)) {
    cat(sprintf("  %s: %.3f\n", sampler_types[i], z_scores[i]))
  }
  
  return(sim_data)
}

# Generate simulated data
sim_data_1.1 <- simulate_model_1.1(avg_conc = 8)

```

Model Fit
```{r, eval=FALSE, echo=FALSE}
# fit model 1.1
# Prepare the data
data1.1 <- list(
  C_obs = standardize(sim_data_1.1$C_obs),       # Standardized Obs concentrations
  S = as.numeric(as.factor(sim_data_1.1$S)),     # Sampler types as integers
  N = nrow(sim_data_1.1),                        # Number of observations
  K = length(unique(sim_data_1.1$S))             # Number of sampler types
)

# Fit Model 1.1
m1.1 <- ulam(
  alist(
    # Model for observed results
    C_obs ~ dnorm(mu, sigma),
    mu <- a[S],                  # Intercept for sampler type
    a[S] ~ dnorm(0, 0.5),        # Prior for intercepts
    sigma ~ dexp(1)              # Prior for measurement error
  ),
  data = data1.1,
  chains = 4,
  cores = 4,
)
```

Summary of results with precis()
```{r, eval=FALSE, echo=FALSE}
# Use the function to display results
print_precis_with_correct_legend(m1.1, sim_data_1.1)
```

Results: Model 1.1 outputted expected z-scores for the true intercepts of the sampler types. The sampler effect intercepts were correctly estimated, with a correct std. deviation of 0.2.

### Model 1.2 - Multilevel model with sampler and analyte effects
Data simulation 
```{r, eval=FALSE, echo=FALSE}
simulate_model_1.2 <- function(n_per_type = 100, noise_sd = 0.2, seed = 45) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0) # Multiplicative effects
  
  # Define analytes' base means and standard deviations
  base_means <- c(NO3 = 8, NO2 = 0.1, TKN = 5, pH = 7, TP = 0.8, OP = 0.3, EC = 0.15, TSS = 1000, TDS = 500)
  base_sd <- c(NO3 = 1, NO2 = 0.01, TKN = 1, pH = 0.1, TP = 0.1, OP = 0.05, EC = 0.01, TSS = 200, TDS = 50)
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Create all combinations of analytes and sampler types
  sim_data <- expand.grid(
    analyte_abbr = seq_along(base_means), # Numeric index for analytes
    S = sampler_types,
    replicate = seq_len(n_per_type)       # Number of replicates per sampler type
  )
  
  # Map analyte_abbr back to analyte names for clarity
  analyte_map <- names(base_means)
  sim_data$analyte_name <- analyte_map[sim_data$analyte_abbr]
  
  # Generate observed concentrations
  sim_data$C_obs <- mapply(function(analyte, sampler) {
    mean_conc <- base_means[analyte]
    sd_conc <- base_sd[analyte]
    sampler_effect <- true_intercepts[sampler]
    rnorm(1, mean = mean_conc * sampler_effect, sd = sd_conc)
  }, analyte = sim_data$analyte_name, sampler = sim_data$S)
  
  # Standardize observed concentrations by analyte
  sim_data <- sim_data %>%
    group_by(analyte_abbr) %>%
    mutate(
      C_obs_standardized = scale(C_obs), # Standardized concentrations
      mean_obs = mean(C_obs),           # Mean of observed concentrations
      sd_obs = sd(C_obs)                # SD of observed concentrations
    ) %>%
    ungroup()
  
  # Calculate z-score equivalents of true intercepts for each analyte
  z_scores <- matrix(NA, nrow = length(base_means), ncol = length(sampler_types))
  for (idx in seq_along(base_means)) {
    analyte <- names(base_means)[idx]
    mean_conc <- base_means[analyte]
    sd_conc <- base_sd[analyte]
    z_scores[idx, ] <- sapply(sampler_types, function(sampler) {
      true_mean <- mean_conc * true_intercepts[sampler]
      z_score <- (true_mean - mean(sim_data$C_obs[sim_data$analyte_abbr == idx])) / 
                 sd(sim_data$C_obs[sim_data$analyte_abbr == idx])
      return(z_score)
    })
  }
  
  # Assign proper row and column names to z_scores
  dimnames(z_scores) <- list(names(base_means), sampler_types)
  
  # Print z-score equivalents
  cat("Z-Score Equivalents of True Intercepts by Analyte:\n")
  print(z_scores)
  
  # Drop unnecessary replicate column and keep only relevant columns
  sim_data <- sim_data %>% select(analyte_abbr, S, C_obs, C_obs_standardized)
  
  return(sim_data)
}

# Generate simulated data for Model 1.2
sim_data_1.2 <- simulate_model_1.2()

# print averages for C_obs per analyte_abbr stratified by sampler type as separate columns
sim_data_1.2 %>%
  group_by(analyte_abbr, S) %>%
  summarize(mean_C_obs = mean(C_obs), .groups = "drop") %>%
  spread(key = S, value = mean_C_obs) %>%
  print(n = Inf)

```

Model fit
```{r, eval=FALSE, echo=FALSE}
# Define data for Model 1.2
data1.2 <- list(
  C_obs = sim_data_1.2$C_obs_standardized,      # Standardized observed concentrations
  S = as.numeric(as.factor(sim_data_1.2$S)),    # Sampler type index (1-4)
  A = sim_data_1.2$analyte_abbr,                # Analyte index (1-9)
  N = nrow(sim_data_1.2),                       # Number of observations
  K_S = length(unique(sim_data_1.2$S)),         # Number of sampler types
  K_A = length(unique(sim_data_1.2$analyte_abbr)) # Number of analytes
)

# Fit Model 1.2
m1.2 <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure: interaction between analyte and sampler type
    mu <- alpha[A] + beta[A, S],
    
    # Priors for analyte-specific intercepts
    matrix[A, S]:beta ~ dnorm(0, 0.5),
    alpha[A] ~ dnorm(a_bar, sigma_a),
    
    # Hyper-priors
    a_bar ~ dnorm(0, 0.5),
    sigma_a ~ dexp(1),
    
    # Prior for measurement error
    sigma ~ dexp(1)
  ),
  data = data1.2,
  chains = 4,
  cores = 4
)

```

Summary of results 
```{r, eval=FALSE, echo=FALSE}
# Use the function to display results
print_precis_with_correct_legend(m1.2, sim_data_1.2)
```

Posterior predictions
```{r, eval=FALSE, echo=FALSE}
# Extract the posterior samples
post <- extract.samples(m1.2)

# Create a link function
link_function <- function(post, data) {
  # Extract necessary dimensions
  n_samples <- nrow(post$beta[, , 1])  # Number of posterior samples
  n_analytes <- data$K_A               # Number of analytes
  n_samplers <- data$K_S               # Number of sampler types
  
  # Initialize matrix to store predictions
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers))
  
  # Generate predictions for each analyte-sampler combination
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      predictions[, a, s] <- post$alpha[, a] + post$beta[, a, s]
    }
  }
  
  return(predictions)
}

# Apply the link function to generate posterior predictions
posterior_predictions <- link_function(post, data1.2)

# Back-transform predictions
back_transformed_predictions <- array(NA, dim = dim(posterior_predictions))

for (a in 1:data1.2$K_A) {
  # Extract mean and SD for the analyte
  analyte_mean <- mean(sim_data_1.2$C_obs[sim_data_1.2$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.2$C_obs[sim_data_1.2$analyte_abbr == a])
  
  # Back-transform predictions for the analyte
  back_transformed_predictions[, a, ] <- posterior_predictions[, a, ] * analyte_sd + analyte_mean
}

# Summarize predictions
prediction_summary <- data.frame()

for (a in 1:data1.2$K_A) {
  for (s in 1:data1.2$K_S) {
    # Extract posterior samples for this analyte-sampler combination
    samples <- back_transformed_predictions[, a, s]
    
    # Compute summary statistics
    summary_row <- data.frame(
      analyte_abbr = a,
      sampler_type = levels(sim_data_1.2$S)[s],
      mean_prediction = mean(samples),
      prediction_5.5 = quantile(samples, 0.055),
      prediction_94.5 = quantile(samples, 0.945)
    )
    
    prediction_summary <- rbind(prediction_summary, summary_row)
  }
}

# View summarized predictions
# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table <- prediction_summary %>%
  select(analyte_abbr, sampler_type, mean_prediction) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table
```

Frequentist Model Equivalent for Sanity Check
```{r, eval=FALSE, echo=FALSE}
# frequentist model to verify model form
# Fit the linear model
lm_fit <- lm(C_obs ~ as.factor(analyte_abbr) + as.factor(analyte_abbr):S, data = sim_data_1.2)

# Summarize the model
summary(lm_fit)

# Generate predictions using the frequentist linear model
sim_data_1.2$lm_predicted <- predict(lm_fit)

# Summarize predictions into a table
lm_summary_table <- sim_data_1.2 %>%
  group_by(analyte_abbr, S) %>%
  summarize(mean_prediction = mean(lm_predicted), .groups = "drop") %>%
  pivot_wider(names_from = S, values_from = mean_prediction)

lm_summary_table

```

Results: Model 1.2 was successful in estimating analyte and sampler effects in a single model with varying standard deviations correctly.

### Model 1.3 - Multilevel model with sampler, analyte, and block effects
Data simulation
```{r, eval=FALSE, echo=FALSE}
simulate_model_1.3 <- function(n_per_type = 100, noise_sd = 0.2, seed = 45) {
  # Define sampler types and their true intercepts
  sampler_types <- c("LCS", "ISCO", "GB", "GBH")
  true_intercepts <- c(LCS = 0.7, ISCO = 0.3, GB = 1.2, GBH = 1.0) # Multiplicative effects
  
  # Define analytes' base means and standard deviations
  base_means <- c(NO3 = 8, NO2 = 0.1, TKN = 5, pH = 7, TP = 0.8, OP = 0.3, EC = 0.15, TSS = 1000, TDS = 500)
  base_sd <- c(NO3 = 1, NO2 = 0.01, TKN = 1, pH = 0.1, TP = 0.1, OP = 0.05, EC = 0.01, TSS = 200, TDS = 50)
  
  # Define block-specific effects as Â±0.2 SD
  block_effects <- c(Block1 = 0, Block2 = 0.5) # Expressed in SDs of the analyte; block 1 will unaffect results
  
  # Set seed for reproducibility
  set.seed(seed)
  
  # Create all combinations of analytes, sampler types, and blocks
  sim_data <- expand.grid(
    analyte_abbr = seq_along(base_means), # Numeric index for analytes
    S = sampler_types,
    block = names(block_effects),
    replicate = seq_len(n_per_type / 2)   # Half the replicates per block
  )
  
  # Map analyte_abbr back to analyte names for clarity
  analyte_map <- names(base_means)
  sim_data$analyte_name <- analyte_map[sim_data$analyte_abbr]
  
  # Generate observed concentrations
  sim_data$C_obs <- mapply(function(analyte, sampler, block) {
    mean_conc <- base_means[analyte]
    sd_conc <- base_sd[analyte]
    sampler_effect <- true_intercepts[sampler]
    block_effect <- block_effects[block] * sd_conc
    rnorm(1, mean = mean_conc * sampler_effect + block_effect, sd = sd_conc)
  }, analyte = sim_data$analyte_name, sampler = sim_data$S, block = sim_data$block)
  
  # Standardize observed concentrations by analyte
  sim_data <- sim_data %>%
    group_by(analyte_abbr) %>%
    mutate(
      C_obs_standardized = scale(C_obs)
    ) %>%
    ungroup()
  
  # Return relevant columns
  sim_data <- sim_data %>% select(analyte_abbr, S, block, C_obs, C_obs_standardized)
  
  return(sim_data)
}

# Generate standardized simulated data for Model 1.3
sim_data_1.3 <- simulate_model_1.3()

# Summarize the averages of C_obs per analyte_abbr stratified by sampler type and block
sim_data_1.3 %>%
  group_by(analyte_abbr, S, block) %>%
  summarize(
    mean_C_obs = mean(C_obs),
    #mean_C_obs_standardized = mean(C_obs_standardized), # Validate standardization
    .groups = "drop"
  ) %>%
  spread(key = S, value = mean_C_obs) %>%
  print(n = Inf)

```

Model fit
```{r, eval=FALSE, echo=FALSE}
# Prepare data for Model 1.3
data1.3 <- list(
  C_obs = sim_data_1.3$C_obs_standardized,   # Observed concentrations
  S = as.numeric(as.factor(sim_data_1.3$S)), # Sampler type index (1-4)
  A = sim_data_1.3$analyte_abbr,             # Analyte index (1-9)
  B = as.numeric(as.factor(sim_data_1.3$block)), # Block index (1-2)
  N = nrow(sim_data_1.3),                    # Number of observations
  K_S = length(unique(sim_data_1.3$S)),      # Number of sampler types
  K_A = length(unique(sim_data_1.3$analyte_abbr)), # Number of analytes
  K_B = length(unique(sim_data_1.3$block))   # Number of blocks
)

# Fit Model 1.3 - non-centered
m1.3 <- ulam(
  alist(
    # Observation model
    C_obs ~ dnorm(mu, sigma),
    
    # Mean structure: interaction between analyte, sampler, and block
    mu <- alpha[A] + beta[A, S] + gamma[B],
    
    # Non-centered parameterization for analyte-specific intercepts
    transpars> vector[K_A]:alpha <<- a_bar + z_alpha * sigma_a,
    vector[K_A]:z_alpha ~ normal(0, 1),
    
    # Non-centered parameterization for block-specific intercepts
    transpars> vector[K_B]:gamma <<- g_bar + z_gamma * sigma_g,
    vector[K_B]:z_gamma ~ normal(0, 1),
    
    # Priors for sampler-specific effects
    matrix[K_A, K_S]:beta ~ normal(0, 1),
    
    # Hyper-priors
    a_bar ~ normal(0, 1),
    sigma_a ~ exponential(1),
    g_bar ~ normal(0, 0.5),
    sigma_g ~ exponential(1),
    
    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = data1.3,
  chains = 4,
  cores = 4
)


```

Summary of results
```{r, eval=FALSE, echo=FALSE}
precis(m1.3, depth=2)
```

Posterior predictions
```{r, eval=FALSE, echo=FALSE}
# Extract posterior samples
post <- extract.samples(m1.3)

# Updated link function for posterior predictions
link_function <- function(post, data) {
  n_samples <- nrow(post$beta[, , 1])  # Number of posterior samples
  n_analytes <- data$K_A               # Number of analytes
  n_samplers <- data$K_S               # Number of sampler types
  n_blocks <- data$K_B                 # Number of blocks
  
  # Initialize predictions array
  predictions <- array(NA, dim = c(n_samples, n_analytes, n_samplers, n_blocks))
  
  # Generate predictions
  for (a in 1:n_analytes) {
    for (s in 1:n_samplers) {
      for (b in 1:n_blocks) {
        # Compute predictions in z-score form
        predictions[, a, s, b] <- post$a_bar +
                                  post$z_alpha[, a] * post$sigma_a +
                                  post$beta[, a, s] +
                                  post$g_bar +
                                  post$z_gamma[, b] * post$sigma_g
      }
    }
  }
  
  return(predictions)
}

# Generate predictions
posterior_predictions <- link_function(post, data1.3)

# Initialize array for back-transformed predictions
back_transformed_predictions <- array(NA, dim = dim(posterior_predictions))

# Back-transform predictions for each analyte
for (a in 1:data1.3$K_A) {
  # Extract mean and SD for the analyte
  analyte_mean <- mean(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  analyte_sd <- sd(sim_data_1.3$C_obs[sim_data_1.3$analyte_abbr == a])
  
  # Back-transform predictions for the analyte
  back_transformed_predictions[, a, , ] <- posterior_predictions[, a, , ] * analyte_sd + analyte_mean
}


# Summarize posterior predictions
# Initialize a summary dataframe
prediction_summary <- data.frame()

# Summarize predictions for each analyte, sampler, and block
for (a in 1:data1.3$K_A) {
  for (s in 1:data1.3$K_S) {
    for (b in 1:data1.3$K_B) {
      # Extract samples for the current analyte, sampler, and block
      samples <- back_transformed_predictions[, a, s, b]
      
      # Add summary statistics to the dataframe
      summary_row <- data.frame(
        analyte_abbr = a,
        sampler_type = as.character(levels(sim_data_1.3$S)[s]),
        block = as.character(levels(sim_data_1.3$block)[b]),
        mean_prediction = mean(samples),
        prediction_5.5 = quantile(samples, 0.055),
        prediction_94.5 = quantile(samples, 0.945)
      )
      
      prediction_summary <- rbind(prediction_summary, summary_row)
    }
  }
}

# Refine the summary table: Rows as analytes, columns as sampler types
refined_summary_table <- prediction_summary %>%
  select(analyte_abbr, sampler_type, mean_prediction, block) %>%
  pivot_wider(names_from = sampler_type, values_from = mean_prediction)

# View the refined summary table
refined_summary_table
```

Results: Model 1.3 appears to work *okay*, but the block effects don't come out as expected when not zero.  For example, in this case, the block 1 effect is 0 and the analyte concentrations for each sampler are accurate.  However, block 2 had an effect of 0.5 std. deviations for each analyte.  The result doesn't *exactly* match the simulation, but it's close.  The trends are captured, but the magnitudes are not.  Will require more investigation.  Will likely move to a MVN model without block effects for now

### Model 1.4 - Multilevel model with sampler, analyte, and no block effects with MVN distribution between analytes

**In Development**

Data simulation
```{r, eval=FALSE, echo=FALSE}
```

Model fit
```{r, eval=FALSE, echo=FALSE}
m1.4_centered <- ulam(
  alist(
    # Observation model
    C_obs_standardized ~ dnorm(mu, sigma),

    # Mean structure
    mu <- alpha[A] + beta[A, S] + gamma[B],

    # Multivariate normal prior for analyte-specific intercepts
    vector[K_A]:alpha ~ multi_normal(mu_alpha, Sigma_alpha),
    vector[K_A]:mu_alpha ~ normal(0, 1),  # Mean vector for analytes
    matrix[K_A, K_A]:Sigma_alpha <- diag_pre_multiply(sigma_alpha, Rho_alpha),
    cholesky_factor_corr[K_A]:Rho_alpha ~ lkj_corr_cholesky(2),
    vector[K_A]:sigma_alpha ~ exponential(1),

    # Priors for sampler effects
    matrix[K_A, K_S]:beta ~ normal(0, 1),

    # Priors for block effects
    vector[K_B]:gamma ~ normal(0, 0.5),

    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = data1.3,
  chains = 4,
  cores = 4
)

m1.4_noncentered <- ulam(
  alist(
    # Observation model
    C_obs_standardized ~ dnorm(mu, sigma),

    # Mean structure
    mu <- alpha[A] + beta[A, S] + gamma[B],

    # Non-centered MVN for analyte-specific intercepts
    transpars> vector[K_A]:alpha <<- mu_alpha + L_Rho_alpha * z_alpha,
    vector[K_A]:z_alpha ~ normal(0, 1),  # Standard normal vector
    vector[K_A]:mu_alpha ~ normal(0, 1),  # Mean vector for analytes
    cholesky_factor_corr[K_A]:L_Rho_alpha ~ lkj_corr_cholesky(2),  # Cholesky factor
    vector[K_A]:sigma_alpha ~ exponential(1),  # Standard deviations
    gq> matrix[K_A, K_A]:Rho_alpha <<- Chol_to_Corr(L_Rho_alpha),  # Correlation matrix

    # Priors for sampler effects
    matrix[K_A, K_S]:beta ~ normal(0, 1),

    # Priors for block effects
    vector[K_B]:gamma ~ normal(0, 0.5),

    # Prior for measurement error
    sigma ~ exponential(1)
  ),
  data = data1.3,
  chains = 4,
  cores = 4
)

```

Summary of results
```{r, eval=FALSE, echo=FALSE}
#precis(fit_m1.4_centered, depth = 2)
precis(fit_m1.4_noncentered, depth = 2)

```

Posterior predictions
```{r, eval=FALSE, echo=FALSE}
post <- extract.samples(fit_m1.4_noncentered)
summary(post$Rho_alpha)

```

Results: 

## Final model selection, graphing, and interpretation

## Conclusion
The aim of this study is to investigate the total effect of sampler method on water quality measurements for mulitple analytes tested in our study. 

In this project, we have demonstrated how to fit multilevel models to data with varying standard deviations. We have shown how to simulate data, fit models, and generate posterior predictions. We have also demonstrated how to back-transform predictions to the original scale. The models we have fitted have successfully estimated the effects of analytes, sampler types, and blocks on the outcome variable. We have also shown how to compare the results of Bayesian models with frequentist models for sanity checks. 



